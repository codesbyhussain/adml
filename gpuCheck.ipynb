{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ff8283-b8bf-4a90-ac4e-cdeea3fb0fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA RTX A2000 12GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84da9d80-5c9c-480f-9606-d7f89412f385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n",
      "True\n",
      "1\n",
      "NVIDIA RTX A2000 12GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)        # Should show 11.7 or similar\n",
    "print(torch.cuda.is_available()) # Should be True\n",
    "print(torch.cuda.device_count()) # Should show 1\n",
    "print(torch.cuda.get_device_name(0)) # Should show RTX A2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece7edd3-561e-497c-b52b-86c554f90a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available for YOLO: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 701, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 469, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 379, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 899, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 471, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 632, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hmanasi1\\AppData\\Local\\Temp\\1\\ipykernel_30976\\3419479429.py\", line 1, in <module>\n",
      "    from ultralytics import YOLO\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\__init__.py\", line 38, in __getattr__\n",
      "    return getattr(importlib.import_module(\"ultralytics.models\"), name)\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\models\\__init__.py\", line 3, in <module>\n",
      "    from .fastsam import FastSAM\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\models\\fastsam\\__init__.py\", line 3, in <module>\n",
      "    from .model import FastSAM\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\models\\fastsam\\model.py\", line 8, in <module>\n",
      "    from ultralytics.engine.model import Model\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 14, in <module>\n",
      "    from ultralytics.engine.results import Results\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\engine\\results.py\", line 18, in <module>\n",
      "    from ultralytics.data.augment import LetterBox\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\data\\__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDataset\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 18, in <module>\n",
      "    from ultralytics.data.utils import FORMATS_HELP_MSG, HELP_URL, IMG_FORMATS, check_file_speeds\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 20, in <module>\n",
      "    from ultralytics.nn.autobackend import check_class_names\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\nn\\__init__.py\", line 3, in <module>\n",
      "    from .tasks import (\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 13, in <module>\n",
      "    from ultralytics.nn.autobackend import check_class_names\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py\", line 73, in <module>\n",
      "    class AutoBackend(nn.Module):\n",
      "  File \"C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py\", line 141, in AutoBackend\n",
      "    device: torch.device = torch.device(\"cpu\"),\n",
      "C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:141: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "print(\"CUDA available for YOLO:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b980f6e9-ef33-44b3-9165-73bb7bff174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592ced6-755e-46be-9dc0-2065a22a6094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c84984-793c-47ea-9dd5-999dd7795c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 19 20:10:35 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.01       Driver Version: 516.01       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A200... WDDM  | 00000000:B3:00.0 Off |                  Off |\n",
      "| 30%   30C    P8     6W /  70W |    881MiB / 12282MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2308    C+G   ...ck\\app-4.46.101\\slack.exe    N/A      |\n",
      "|    0   N/A  N/A      2596    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      9116    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     10040    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10572    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0   N/A  N/A     10620    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     13788    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     15044    C+G   ...g\\Dropbox\\bin\\Dropbox.exe    N/A      |\n",
      "|    0   N/A  N/A     25124    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     30124    C+G   ...ck\\app-4.46.101\\slack.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce789fb3-f277-4faa-8ca9-3e04a4e9cfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 19 21:41:16 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.01       Driver Version: 516.01       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A200... WDDM  | 00000000:B3:00.0 Off |                  Off |\n",
      "| 30%   29C    P8     6W /  70W |    717MiB / 12282MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2308    C+G   ...ck\\app-4.46.101\\slack.exe    N/A      |\n",
      "|    0   N/A  N/A      2596    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      9116    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     10040    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10572    C+G   ...w5n1h2txyewy\\SearchUI.exe    N/A      |\n",
      "|    0   N/A  N/A     10620    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     13788    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     15044    C+G   ...g\\Dropbox\\bin\\Dropbox.exe    N/A      |\n",
      "|    0   N/A  N/A     25124    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     30124    C+G   ...ck\\app-4.46.101\\slack.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54db4c0-5f8a-40f4-8694-2443227c9841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py311 GPU",
   "language": "python",
   "name": "py311_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

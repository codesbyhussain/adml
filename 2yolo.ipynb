{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164863ad-0847-4e4b-aac1-e2aac266dd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting annotations to YOLO format...\n",
      "Splitting data into train/validation sets...\n",
      "Created C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\processed_yolo\\dataset.yaml\n",
      "\n",
      "Data preparation complete.\n",
      "Train images: 120, Val images: 30\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Adjust these paths to your project structure\n",
    "RAW_DATA_DIR = Path(\"data/raw\")\n",
    "PROCESSED_DATA_DIR = Path(\"data/processed_yolo\")\n",
    "IMAGES_DIR = PROCESSED_DATA_DIR / \"images\"\n",
    "LABELS_DIR = PROCESSED_DATA_DIR / \"labels\"\n",
    "SOLAFUNE_JSON_PATH = RAW_DATA_DIR / \"train_annotations.json\" # Assumed name\n",
    "\n",
    "# --- MAIN SCRIPT ---\n",
    "\n",
    "def parse_solafune_json(json_path, raw_image_dir):\n",
    "    \"\"\"\n",
    "    Parses the proprietary Solafune JSON file.\n",
    "    This version is adapted for the user-provided JSON structure where\n",
    "    annotations are nested within each image object.\n",
    "    \n",
    "    Args:\n",
    "        json_path (Path): Path to the Solafune annotation JSON file.\n",
    "        raw_image_dir (Path): Path to the directory containing the raw images.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping image filenames to their annotations.\n",
    "    \"\"\"\n",
    "    annotations = {}\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Iterate through the list of image objects in the JSON\n",
    "    for image_data in data.get('images',):\n",
    "        filename = image_data['file_name']\n",
    "        \n",
    "        if filename not in annotations:\n",
    "            annotations[filename] = {\n",
    "                'size': (image_data['width'], image_data['height']),\n",
    "                'polygons': [] \n",
    "            }\n",
    "        \n",
    "        # Iterate through the annotations nested within this image\n",
    "        for ann in image_data.get('annotations',):\n",
    "            class_name = ann.get('class', 'unknown')\n",
    "            flat_points = ann['segmentation']\n",
    "            points = list(zip(flat_points[::2], flat_points[1::2]))\n",
    "\n",
    "            annotations[filename]['polygons'].append({\n",
    "                'class': class_name,\n",
    "                'points': points\n",
    "            })\n",
    "            \n",
    "    return annotations\n",
    "\n",
    "def convert_to_yolo_format(all_annotations, class_map):\n",
    "    \"\"\"\n",
    "    Converts the parsed annotations to YOLO segmentation format and writes.txt files.\n",
    "    \"\"\"\n",
    "    print(\"Converting annotations to YOLO format...\")\n",
    "    LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for filename, data in all_annotations.items():\n",
    "        img_w, img_h = data['size']\n",
    "        yolo_lines = []\n",
    "\n",
    "        for polygon in data['polygons']:\n",
    "            class_name = polygon['class']\n",
    "            if class_name not in class_map:\n",
    "                continue\n",
    "            \n",
    "            class_index = class_map[class_name]\n",
    "            \n",
    "            # Normalize points and flatten the list\n",
    "            normalized_points = []\n",
    "            for x, y in polygon['points']:\n",
    "                norm_x = x / img_w\n",
    "                norm_y = y / img_h\n",
    "                normalized_points.extend([f\"{norm_x:.6f}\", f\"{norm_y:.6f}\"])\n",
    "            \n",
    "            if normalized_points:\n",
    "                line = f\"{class_index} \" + \" \".join(normalized_points)\n",
    "                yolo_lines.append(line)\n",
    "\n",
    "        # Write the.txt file for the image\n",
    "        label_path = LABELS_DIR / f\"{Path(filename).stem}.txt\"\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_lines))\n",
    "\n",
    "def create_dataset_yaml(output_dir, class_names):\n",
    "    \"\"\"\n",
    "    Creates the dataset.yaml file required for YOLO training.\n",
    "    \"\"\"\n",
    "    output_dir = output_dir.resolve()  # convert to absolute path\n",
    "    content = f\"\"\"\n",
    "train: {output_dir}/images/train/\n",
    "val: {output_dir}/images/val/\n",
    "\n",
    "# Classes\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "    with open(output_dir / \"dataset.yaml\", 'w') as f:\n",
    "        f.write(content)\n",
    "    print(f\"Created {output_dir / 'dataset.yaml'}\")\n",
    "\n",
    "def copy_files(file_list, split):\n",
    "    for filename in file_list:\n",
    "        # Paths\n",
    "        src_image = RAW_DATA_DIR / \"train_images\" / filename\n",
    "        dst_image = IMAGES_DIR / split / filename\n",
    "\n",
    "        label_filename = f\"{Path(filename).stem}.txt\"\n",
    "        src_label = LABELS_DIR / label_filename\n",
    "        dst_label = LABELS_DIR / split / label_filename\n",
    "\n",
    "        # Copy image if it exists\n",
    "        if src_image.exists():\n",
    "            shutil.copy(src_image, dst_image)\n",
    "        else:\n",
    "            print(f\"Warning: Image {src_image} does not exist, skipping.\")\n",
    "\n",
    "        # Copy label if it exists\n",
    "        if src_label.exists():\n",
    "            shutil.copy(src_label, dst_label)\n",
    "        else:\n",
    "            print(f\"Warning: Label {src_label} does not exist, skipping.\")\n",
    "\n",
    "def main():\n",
    "    # --- 1. Setup Directories ---\n",
    "    shutil.rmtree(PROCESSED_DATA_DIR, ignore_errors=True)\n",
    "    for split in ['train', 'val']:\n",
    "        (IMAGES_DIR / split).mkdir(parents=True, exist_ok=True)\n",
    "        (LABELS_DIR / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- 2. Parse Annotations ---\n",
    "    # This assumes your raw images are in a subdirectory like 'data/raw/images'\n",
    "    all_annotations = parse_solafune_json(SOLAFUNE_JSON_PATH, RAW_DATA_DIR / \"images\")\n",
    "    if not all_annotations:\n",
    "        print(\"Parsing failed. Please check the `parse_solafune_json` function and JSON path.\")\n",
    "        return\n",
    "\n",
    "    class_map = {\n",
    "    'group_of_trees': 0,\n",
    "    'individual_tree': 1\n",
    "}\n",
    "    class_names = list(class_map.keys())\n",
    "\n",
    "    # --- 3. Convert to YOLO format (temporary) ---\n",
    "    convert_to_yolo_format(all_annotations, class_map)\n",
    "\n",
    "    # --- 4. Split Data and Organize Files ---\n",
    "    print(\"Splitting data into train/validation sets...\")\n",
    "    image_files = list(all_annotations.keys())\n",
    "    train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "    copy_files(train_files, 'train')\n",
    "    copy_files(val_files, 'val')\n",
    "\n",
    "    # --- 5. Create YAML file ---\n",
    "    create_dataset_yaml(PROCESSED_DATA_DIR, class_names)\n",
    "    \n",
    "    print(\"\\nData preparation complete.\")\n",
    "    print(f\"Train images: {len(train_files)}, Val images: {len(val_files)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb94638-beb7-414f-8aaa-2cb7d9a83e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting model training...\n",
      "Ultralytics 8.3.217  Python-3.11.13 torch-2.0.1+cu117 CUDA:0 (NVIDIA RTX A2000 12GB, 12281MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/processed_yolo/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=tree_canopy_experiment_12, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\train\\tree_canopy_experiment_12, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2771318  ultralytics.nn.modules.head.Segment          [2, 32, 128, [128, 256, 512]] \n",
      "YOLOv8s-seg summary: 151 layers, 11,790,870 parameters, 11,790,854 gradients, 40.2 GFLOPs\n",
      "\n",
      "Transferred 411/417 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 205.241.0 MB/s, size: 3072.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\processed_yolo\\labels\\train... 120 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 120/120 61.3it/s 2.0s0.2s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\processed_yolo\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mImageCompression.__init__() got an unexpected keyword argument 'quality_range'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 223.346.6 MB/s, size: 3072.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\processed_yolo\\labels\\val... 30 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 30/30 66.9it/s 0.4s0.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\processed_yolo\\labels\\val.cache\n",
      "Plotting labels to C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\train\\tree_canopy_experiment_12\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\train\\tree_canopy_experiment_12\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      9.27G      3.026      4.956        3.8      1.977       1768        640: 100% ━━━━━━━━━━━━ 15/15 0.8it/s 18.4s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.0it/s 1.9s4.1s\n",
      "                   all         30       7107      0.159      0.119      0.123     0.0685      0.155      0.117      0.119     0.0562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      7.19G       2.48      4.136      2.001      1.424       1925        640: 100% ━━━━━━━━━━━━ 15/15 1.2it/s 12.2s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.9s4.4s\n",
      "                   all         30       7107      0.171      0.172      0.115     0.0565      0.187      0.168      0.119     0.0513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      8.82G      2.335      3.815      1.664      1.286       2643        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.9s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.7s3.7s\n",
      "                   all         30       7107      0.239      0.201      0.173     0.0956      0.229      0.193      0.167     0.0656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      8.38G      2.146      3.712      1.488      1.215       2348        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.4s\n",
      "                   all         30       7107      0.238      0.178      0.178     0.0889      0.237      0.169      0.163      0.063\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      6.81G       2.16      3.705      1.533      1.218       2783        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.4s\n",
      "                   all         30       7107      0.253      0.181      0.183     0.0932      0.241      0.171      0.172     0.0685\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      10.5G      2.092      3.474      1.464      1.155       4283        640: 100% ━━━━━━━━━━━━ 15/15 1.4it/s 10.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.7s\n",
      "                   all         30       7107      0.263      0.163      0.171     0.0919      0.261      0.161      0.163     0.0623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      7.28G      2.127      3.497       1.39       1.17       2795        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s3.9s\n",
      "                   all         30       7107      0.301      0.131       0.17     0.0923      0.203      0.136      0.143     0.0643\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      6.58G      1.996      3.414      1.292       1.16       2120        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.8s\n",
      "                   all         30       7107      0.251      0.167        0.2      0.108      0.247      0.153       0.18     0.0736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      8.27G      2.048      3.283      1.349      1.145       2431        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.9s4.3s\n",
      "                   all         30       7107      0.267      0.193       0.21      0.113      0.247       0.18       0.19     0.0797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      10.1G      1.922      3.323      1.237      1.137       2542        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.1s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.7s\n",
      "                   all         30       7107      0.317      0.244      0.236      0.128      0.296      0.216      0.208     0.0865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      8.15G      1.997       3.29      1.316      1.122       2277        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.354      0.261      0.245      0.125      0.322      0.234      0.214      0.087\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      9.23G       2.05      3.347      1.297      1.138       3013        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.8s\n",
      "                   all         30       7107      0.335      0.271      0.257      0.135      0.304      0.232      0.206      0.087\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      7.32G      1.908      3.194      1.255      1.135       3783        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.2s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.7s\n",
      "                   all         30       7107      0.308       0.23      0.234      0.129      0.289      0.218      0.217     0.0971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      7.26G      1.935      3.171      1.192      1.098       3297        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.1s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.9s4.2s\n",
      "                   all         30       7107      0.308      0.247      0.241      0.131      0.282      0.224      0.218     0.0967\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      6.66G      1.927      3.177      1.218        1.1       3098        640: 100% ━━━━━━━━━━━━ 15/15 0.7it/s 22.1s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.9s4.4s\n",
      "                   all         30       7107      0.399      0.244      0.258      0.139      0.394      0.231      0.239      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      9.74G      1.722      2.968      1.084       1.09       1443        640: 100% ━━━━━━━━━━━━ 15/15 0.8it/s 19.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.0s\n",
      "                   all         30       7107      0.335      0.236      0.244      0.136      0.326      0.223      0.223      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      9.21G      1.813      3.093      1.133       1.09       2717        640: 100% ━━━━━━━━━━━━ 15/15 1.2it/s 12.8s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.8s\n",
      "                   all         30       7107      0.389      0.293      0.291      0.153       0.37       0.27      0.261      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100        10G      1.856      3.119       1.14      1.083       2692        640: 100% ━━━━━━━━━━━━ 15/15 0.7it/s 20.0s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.0it/s 2.0s4.7s\n",
      "                   all         30       7107      0.378      0.273      0.276      0.146      0.373      0.264      0.263      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      7.43G      1.927      3.201      1.209        1.1       1497        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.2s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.1s\n",
      "                   all         30       7107      0.396      0.276       0.29      0.153      0.382      0.243      0.261      0.113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      7.45G      1.816      3.012      1.155      1.091       3608        640: 100% ━━━━━━━━━━━━ 15/15 2.0it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.1s\n",
      "                   all         30       7107      0.412      0.296      0.306      0.162      0.389      0.278      0.283      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      7.94G      1.836      3.142      1.094      1.068       2722        640: 100% ━━━━━━━━━━━━ 15/15 0.7it/s 22.2s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.7s\n",
      "                   all         30       7107       0.39       0.28      0.286      0.155      0.373      0.261      0.264      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      7.49G      1.787      3.099      1.108       1.09       2418        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.7s\n",
      "                   all         30       7107      0.429      0.291      0.309      0.165      0.409      0.272      0.285       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      7.72G      1.881      3.101      1.141      1.081       2063        640: 100% ━━━━━━━━━━━━ 15/15 1.9it/s 7.8s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.8s\n",
      "                   all         30       7107      0.393      0.276      0.288      0.152      0.357      0.247      0.259      0.115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      9.52G      1.917      3.138      1.147      1.092       3136        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.2s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.7s\n",
      "                   all         30       7107      0.417      0.288      0.311      0.162       0.41      0.275      0.291      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      9.64G      1.821      3.079      1.101      1.068       3835        640: 100% ━━━━━━━━━━━━ 15/15 2.0it/s 7.4s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.6s\n",
      "                   all         30       7107      0.412      0.311      0.325      0.171      0.365      0.283      0.281      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      7.99G      1.933      3.032      1.193      1.085       2360        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.7s\n",
      "                   all         30       7107      0.443      0.312       0.34      0.187      0.417      0.288       0.31       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      7.91G      1.924       3.05      1.137       1.06       3345        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.1s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.8s\n",
      "                   all         30       7107      0.437        0.3      0.326      0.176      0.396      0.263      0.285      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100       7.1G      1.823      2.968      1.129      1.065       2895        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.0s\n",
      "                   all         30       7107      0.411      0.324      0.331      0.178      0.378      0.297      0.305      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      10.6G      1.765      2.994      1.059      1.057       2235        640: 100% ━━━━━━━━━━━━ 15/15 2.0it/s 7.5s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.1it/s 1.8s4.2s\n",
      "                   all         30       7107      0.389      0.343      0.317      0.172       0.37      0.317      0.298      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      6.44G      1.818      2.945      1.122      1.066       2104        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.9s\n",
      "                   all         30       7107      0.404      0.329      0.316      0.171      0.397      0.298      0.295      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      7.07G      1.845      2.985      1.132      1.064       3032        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.7s\n",
      "                   all         30       7107      0.418      0.325      0.332      0.176      0.403      0.298      0.309      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100       8.9G      1.806      2.938      1.108      1.067       1966        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.424      0.321      0.339      0.182      0.426      0.306      0.323      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      10.2G      1.769      2.909      1.063      1.044       2759        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.1s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.432      0.313      0.335      0.182      0.421      0.296      0.324      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      9.66G      1.753      2.912      1.039      1.045       3449        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.7s\n",
      "                   all         30       7107       0.43      0.316      0.332       0.18      0.413      0.294      0.312      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      8.27G       1.72      2.908      1.028      1.053       2024        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.428        0.3      0.315      0.168      0.391      0.268      0.283      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      6.86G      1.722      2.869      1.021       1.05       3426        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.1s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.7s\n",
      "                   all         30       7107      0.427      0.326       0.33      0.175      0.401      0.293      0.298      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100      10.3G      1.715      2.826      1.001      1.033       3141        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.9s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.8s\n",
      "                   all         30       7107      0.392      0.296      0.299      0.162      0.393      0.257      0.276      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      5.74G      1.775      2.832      1.041      1.026       2243        640: 100% ━━━━━━━━━━━━ 15/15 2.4it/s 6.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.7s\n",
      "                   all         30       7107      0.402      0.295      0.295      0.159      0.367      0.266      0.265      0.122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100        10G      1.744      2.829      1.036      1.044       2732        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.7s\n",
      "                   all         30       7107      0.435      0.316      0.318       0.17      0.404      0.287      0.291      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      10.2G      1.725      2.867      1.019      1.042       1830        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.433      0.329      0.339      0.182      0.418      0.292      0.313      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      10.1G      1.722      2.862      1.021      1.042       4217        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.8s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107       0.45      0.339      0.348      0.187      0.429      0.314      0.325      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      5.75G      1.656      2.748      1.002      1.032       1972        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.0s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.7s\n",
      "                   all         30       7107      0.413      0.334      0.334      0.184       0.41      0.312      0.318       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      8.73G      1.729      2.858      1.029      1.052       2119        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.447       0.35      0.363      0.195      0.437      0.334      0.348      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      8.81G       1.72      2.789      1.037       1.04       3497        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.449      0.344      0.354      0.195       0.42      0.323      0.332      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100      9.53G      1.667      2.748     0.9871      1.025       2531        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.7s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.7s\n",
      "                   all         30       7107      0.458      0.336      0.341      0.188      0.443      0.326      0.329      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      6.63G      1.726      2.788      1.035       1.04       2050        640: 100% ━━━━━━━━━━━━ 15/15 2.4it/s 6.2s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107       0.44      0.346      0.351      0.193      0.449      0.333      0.343      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100      8.58G      1.692      2.865     0.9929      1.039       2229        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.0s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.7s3.7s\n",
      "                   all         30       7107      0.438      0.348      0.354      0.188       0.42      0.321      0.327      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      6.74G      1.795      2.872      1.059       1.04       2889        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.435      0.318      0.329      0.171      0.412      0.293      0.305      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100       9.4G      1.585      2.735     0.9328      1.016       1420        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.444      0.319      0.326      0.174      0.411       0.29      0.297      0.137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      8.84G      1.639      2.734     0.9575      1.021       2255        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.7s\n",
      "                   all         30       7107      0.427      0.328      0.328      0.181      0.408      0.296      0.304      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      6.89G       1.64       2.64     0.9833      1.027       1708        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.4s\n",
      "                   all         30       7107      0.446      0.341      0.342      0.188       0.42       0.32       0.32      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      9.88G      1.709      2.779       1.01      1.029       2163        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.4s\n",
      "                   all         30       7107      0.463      0.339      0.345      0.187       0.44      0.319      0.323      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      6.69G      1.656      2.694     0.9524      1.013       3301        640: 100% ━━━━━━━━━━━━ 15/15 2.4it/s 6.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.455      0.327      0.341      0.184      0.428      0.301      0.314      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      6.92G      1.669      2.727     0.9434      1.018       2884        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.5s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.439       0.31      0.327      0.176      0.409      0.288      0.301       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100       9.9G       1.68      2.794     0.9642      1.028       2994        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.436      0.309      0.331      0.177      0.412      0.288       0.31      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      6.56G      1.694      2.771     0.9851      1.034       2215        640: 100% ━━━━━━━━━━━━ 15/15 1.9it/s 7.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.438      0.333      0.347      0.188      0.409      0.321      0.326      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      9.71G      1.606      2.682      0.927      1.014       1730        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.445      0.349      0.352      0.193      0.423      0.317      0.329      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      7.52G      1.691      2.774     0.9577      1.007       4447        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.2s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.7s\n",
      "                   all         30       7107      0.447      0.346      0.352      0.194       0.42      0.324      0.329      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      7.91G      1.709      2.842     0.9912      1.023       2636        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.7s\n",
      "                   all         30       7107      0.454      0.355      0.361      0.198       0.42       0.33      0.336      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      8.98G      1.636      2.734     0.9477      1.006       3903        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.6s\n",
      "                   all         30       7107      0.456      0.372      0.368      0.197      0.437       0.33      0.335      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100       8.2G      1.715      2.668      1.015      1.016       3506        640: 100% ━━━━━━━━━━━━ 15/15 2.4it/s 6.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.443      0.335      0.343      0.188      0.404      0.303      0.309      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      6.55G      1.644       2.67     0.9559      1.004       2595        640: 100% ━━━━━━━━━━━━ 15/15 2.4it/s 6.2s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.2it/s 1.6s3.6s\n",
      "                   all         30       7107      0.454      0.311      0.333      0.184      0.405      0.288      0.304      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      8.48G      1.769      2.789      1.049      1.022       3403        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.462      0.312      0.343      0.192      0.426      0.306      0.327      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      7.73G      1.669      2.717     0.9884      1.014       3880        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.436      0.348      0.358      0.196      0.411      0.319       0.33      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      6.12G      1.653      2.725     0.9537      1.025       2352        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 7.0s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.459       0.35      0.356      0.193      0.432      0.325       0.33      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      8.91G      1.669      2.686     0.9771      1.009       2897        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 7.0s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.476      0.327      0.342      0.186      0.455      0.299      0.316      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      6.57G      1.698      2.737      0.987      1.024       2544        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.5s\n",
      "                   all         30       7107      0.448      0.354      0.353      0.191      0.422       0.32      0.324       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      8.12G      1.642      2.746     0.9367      1.015       3755        640: 100% ━━━━━━━━━━━━ 15/15 2.0it/s 7.5s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.5s\n",
      "                   all         30       7107      0.441      0.385      0.365      0.199      0.423      0.355      0.344       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      6.31G      1.621       2.69     0.9385      1.013       3780        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.0s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.448      0.369      0.358      0.197      0.427      0.343      0.335      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      6.87G      1.664       2.68      0.946      1.008       1870        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.4s\n",
      "                   all         30       7107      0.458      0.359      0.359      0.197      0.443      0.329      0.335      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100        10G      1.633       2.73     0.9217     0.9997       2202        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107       0.44      0.353      0.351      0.193      0.415      0.325      0.327      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      8.89G      1.672       2.65     0.9642      1.008       2719        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.6s\n",
      "                   all         30       7107      0.467      0.348      0.359      0.198      0.439      0.327      0.337       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      8.07G      1.673      2.723     0.9462      1.016       3741        640: 100% ━━━━━━━━━━━━ 15/15 2.0it/s 7.4s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.5s\n",
      "                   all         30       7107      0.453      0.349       0.36      0.196      0.427      0.322      0.336       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      8.22G       1.64      2.652      0.939      1.005       3993        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.5s\n",
      "                   all         30       7107      0.446      0.336      0.347      0.186      0.412      0.295      0.308      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      8.82G      1.617      2.608     0.9414     0.9969       3254        640: 100% ━━━━━━━━━━━━ 15/15 2.4it/s 6.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.4s\n",
      "                   all         30       7107      0.465      0.342      0.355      0.191      0.422      0.312       0.32      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100       8.1G      1.556      2.672     0.8766     0.9976       1789        640: 100% ━━━━━━━━━━━━ 15/15 2.0it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.5s\n",
      "                   all         30       7107      0.462      0.351      0.358      0.193      0.436      0.332      0.334      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      9.57G      1.609      2.658     0.9137      1.008       2712        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.5s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.449      0.345      0.352      0.191      0.413      0.313      0.319       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100      7.18G       1.58      2.637     0.8993     0.9976       2649        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.446      0.352      0.357      0.193      0.414      0.321      0.324      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100       8.4G      1.652      2.701     0.9216     0.9972       2592        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.475      0.348      0.365      0.196       0.44      0.314      0.329      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      7.13G      1.583      2.612     0.9077      0.992       2185        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.6s\n",
      "                   all         30       7107      0.477      0.352      0.368      0.201      0.444      0.313      0.329      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      8.39G      1.644      2.639     0.9334      1.004       2138        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.494      0.351      0.374      0.201      0.455      0.322      0.342       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      9.57G      1.531      2.585     0.8688     0.9907       1479        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.6s\n",
      "                   all         30       7107      0.482      0.362      0.372      0.201       0.44      0.331      0.343      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      8.06G      1.595      2.648     0.8934      1.007       1348        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.494       0.35      0.372      0.203      0.456       0.32      0.342       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      9.46G      1.556      2.569     0.8653     0.9894       2977        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.479      0.347      0.368      0.202      0.441      0.313      0.332      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      6.26G       1.64      2.634     0.9402      1.001       1906        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.1s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.6s\n",
      "                   all         30       7107       0.47      0.346      0.365      0.202      0.444      0.318      0.335      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      7.72G      1.641      2.722     0.9161     0.9915       2638        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.477       0.35      0.371      0.202      0.449      0.321      0.342      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      10.6G      1.599       2.62     0.8959     0.9959       1658        640: 100% ━━━━━━━━━━━━ 15/15 2.1it/s 7.0s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.471      0.344      0.364      0.199      0.443      0.319      0.338       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      8.73G      1.609      2.639     0.9048     0.9897       2064        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 6.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.5s\n",
      "                   all         30       7107      0.457      0.351      0.364      0.199      0.424      0.326      0.336      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      8.65G      1.525      2.545     0.8595     0.9864       2668        640: 100% ━━━━━━━━━━━━ 15/15 2.3it/s 6.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.5s\n",
      "                   all         30       7107      0.463      0.357       0.37        0.2      0.439      0.313      0.335      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      8.74G      1.567       2.65     0.8571     0.9861       3712        640: 100% ━━━━━━━━━━━━ 15/15 2.2it/s 7.0s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.4s\n",
      "                   all         30       7107      0.473      0.364      0.374      0.203      0.446      0.322      0.338       0.16\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mImageCompression.__init__() got an unexpected keyword argument 'quality_range'\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      9.12G      1.602       2.59     0.9395      1.007       1877        640: 100% ━━━━━━━━━━━━ 15/15 2.0it/s 7.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.478       0.36       0.37      0.202      0.458      0.318      0.337       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      6.45G       1.59      2.605     0.9421      1.003       2123        640: 100% ━━━━━━━━━━━━ 15/15 2.4it/s 6.1s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.484      0.367      0.373      0.202      0.448      0.339      0.342      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100      9.46G      1.595       2.55     0.9408      0.987       1763        640: 100% ━━━━━━━━━━━━ 15/15 2.6it/s 5.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.481      0.375      0.378      0.204      0.449      0.343      0.347      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100      6.95G      1.605      2.581     0.9431      0.998       1263        640: 100% ━━━━━━━━━━━━ 15/15 2.8it/s 5.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.5s\n",
      "                   all         30       7107      0.476      0.382       0.38      0.205      0.455      0.344       0.35      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      8.48G      1.558      2.535     0.8908     0.9978       1995        640: 100% ━━━━━━━━━━━━ 15/15 2.7it/s 5.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.478      0.377      0.376      0.204      0.452      0.342      0.348      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      6.46G      1.593      2.549      0.913     0.9903       1816        640: 100% ━━━━━━━━━━━━ 15/15 2.7it/s 5.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.6s\n",
      "                   all         30       7107       0.48       0.37      0.375      0.203      0.449      0.334      0.344      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      7.23G      1.556      2.541     0.8817     0.9949       1754        640: 100% ━━━━━━━━━━━━ 15/15 2.7it/s 5.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.5s3.5s\n",
      "                   all         30       7107      0.475       0.37      0.372        0.2      0.447      0.329      0.339      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      7.98G        1.6      2.577     0.9063     0.9848       2015        640: 100% ━━━━━━━━━━━━ 15/15 2.7it/s 5.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.473      0.369      0.372        0.2      0.446       0.33      0.337       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      7.79G      1.584      2.571     0.8843     0.9878        951        640: 100% ━━━━━━━━━━━━ 15/15 2.6it/s 5.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.478      0.368      0.372        0.2      0.441      0.329      0.336       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      10.5G      1.576      2.525     0.8873      0.975       2608        640: 100% ━━━━━━━━━━━━ 15/15 2.6it/s 5.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 1.3it/s 1.6s3.5s\n",
      "                   all         30       7107      0.477      0.365      0.373      0.201      0.448      0.326      0.337       0.16\n",
      "\n",
      "100 epochs completed in 0.313 hours.\n",
      "Optimizer stripped from C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\train\\tree_canopy_experiment_12\\weights\\last.pt, 23.9MB\n",
      "Optimizer stripped from C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\train\\tree_canopy_experiment_12\\weights\\best.pt, 23.9MB\n",
      "\n",
      "Validating C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\train\\tree_canopy_experiment_12\\weights\\best.pt...\n",
      "Ultralytics 8.3.217  Python-3.11.13 torch-2.0.1+cu117 CUDA:0 (NVIDIA RTX A2000 12GB, 12281MiB)\n",
      "YOLOv8s-seg summary (fused): 85 layers, 11,780,374 parameters, 0 gradients, 39.9 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 0.6it/s 3.6s3.5s\n",
      "                   all         30       7107      0.477      0.382       0.38      0.205      0.453      0.343      0.349      0.166\n",
      "        group_of_trees         23        811      0.372      0.323      0.261      0.127      0.379      0.303      0.257      0.113\n",
      "       individual_tree         30       6296      0.582      0.441      0.499      0.283      0.527      0.382      0.441      0.218\n",
      "Speed: 1.6ms preprocess, 30.0ms inference, 0.0ms loss, 50.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\train\\tree_canopy_experiment_12\u001b[0m\n",
      "Training complete.\n",
      "Best model saved at: C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\train\\tree_canopy_experiment_12\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATASET_YAML = \"data/processed_yolo/dataset.yaml\"\n",
    "EPOCHS = 100\n",
    "IMAGE_SIZE = 640\n",
    "BATCH_SIZE = 8\n",
    "MODEL_NAME = 'yolov8s-seg.pt' # s=small, n=nano, m=medium, l=large, x=xlarge\n",
    "\n",
    "def train():\n",
    "    # Check for GPU\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load a pretrained YOLOv8 instance segmentation model\n",
    "    model = YOLO(MODEL_NAME)\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Starting model training...\")\n",
    "    results = model.train(\n",
    "        data=DATASET_YAML,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMAGE_SIZE,\n",
    "        batch=BATCH_SIZE,\n",
    "        device=device,\n",
    "        project=\"runs/train\", # Directory to save results\n",
    "        name=\"tree_canopy_experiment_1\" # Sub-directory name for this run\n",
    "    )\n",
    "    print(\"Training complete.\")\n",
    "    print(f\"Best model saved at: {results.save_dir}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5220dcdc-a14b-41b3-88cd-427afe81bbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on images in: data/test/evaluation_images\n",
      "\n",
      "image 1/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_1.tif: 640x640 6 group_of_treess, 105.5ms\n",
      "image 2/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_10.tif: 640x640 13 group_of_treess, 12.8ms\n",
      "image 3/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_11.tif: 640x640 7 group_of_treess, 666.3ms\n",
      "image 4/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_12.tif: 640x640 18 group_of_treess, 60.7ms\n",
      "image 5/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_13.tif: 640x640 (no detections), 52.3ms\n",
      "image 6/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_14.tif: 640x640 4 group_of_treess, 308.1ms\n",
      "image 7/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_15.tif: 640x640 (no detections), 49.4ms\n",
      "image 8/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_16.tif: 640x640 2 group_of_treess, 57.8ms\n",
      "image 9/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_17.tif: 640x640 14 group_of_treess, 49.7ms\n",
      "image 10/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_18.tif: 640x640 3 group_of_treess, 51.1ms\n",
      "image 11/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_19.tif: 640x640 (no detections), 91.8ms\n",
      "image 12/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_2.tif: 640x640 1 group_of_trees, 107.0ms\n",
      "image 13/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_20.tif: 640x640 (no detections), 51.7ms\n",
      "image 14/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_21.tif: 640x640 1 group_of_trees, 46.2ms\n",
      "image 15/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_22.tif: 640x640 3 group_of_treess, 12.8ms\n",
      "image 16/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_23.tif: 640x640 3 group_of_treess, 12.9ms\n",
      "image 17/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_24.tif: 640x640 (no detections), 13.2ms\n",
      "image 18/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_25.tif: 640x640 1 group_of_trees, 11.2ms\n",
      "image 19/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_26.tif: 640x640 2 group_of_treess, 11.3ms\n",
      "image 20/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_27.tif: 640x640 (no detections), 11.5ms\n",
      "image 21/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_28.tif: 640x640 2 group_of_treess, 11.2ms\n",
      "image 22/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_29.tif: 640x640 6 group_of_treess, 11.8ms\n",
      "image 23/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_3.tif: 640x640 1 group_of_trees, 114.3ms\n",
      "image 24/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_30.tif: 640x640 9 group_of_treess, 100.1ms\n",
      "image 25/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_31.tif: 640x640 3 group_of_treess, 11.3ms\n",
      "image 26/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_32.tif: 640x640 16 group_of_treess, 11.3ms\n",
      "image 27/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_33.tif: 640x640 1 group_of_trees, 12.7ms\n",
      "image 28/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_34.tif: 640x640 5 group_of_treess, 12.0ms\n",
      "image 29/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_35.tif: 640x640 (no detections), 17.5ms\n",
      "image 30/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_36.tif: 640x640 1 group_of_trees, 17.4ms\n",
      "image 31/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_37.tif: 640x640 (no detections), 17.9ms\n",
      "image 32/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_38.tif: 640x640 (no detections), 17.9ms\n",
      "image 33/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_4.tif: 640x640 9 group_of_treess, 17.9ms\n",
      "image 34/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_5.tif: 640x640 6 group_of_treess, 18.4ms\n",
      "image 35/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_6.tif: 640x640 3 group_of_treess, 18.4ms\n",
      "image 36/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_7.tif: 640x640 (no detections), 18.7ms\n",
      "image 37/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_8.tif: 640x640 8 group_of_treess, 18.8ms\n",
      "image 38/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\10cm_evaluation_9.tif: 640x640 15 group_of_treess, 19.4ms\n",
      "image 39/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_39.tif: 640x640 24 group_of_treess, 50.7ms\n",
      "image 40/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_40.tif: 640x640 5 group_of_treess, 87.3ms\n",
      "image 41/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_41.tif: 640x640 15 group_of_treess, 22.1ms\n",
      "image 42/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_42.tif: 640x640 (no detections), 25.6ms\n",
      "image 43/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_43.tif: 640x640 6 group_of_treess, 24.4ms\n",
      "image 44/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_44.tif: 640x640 3 group_of_treess, 24.4ms\n",
      "image 45/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_45.tif: 640x640 8 group_of_treess, 24.2ms\n",
      "image 46/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_46.tif: 640x640 (no detections), 94.8ms\n",
      "image 47/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_47.tif: 640x640 6 group_of_treess, 77.3ms\n",
      "image 48/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_48.tif: 640x640 5 group_of_treess, 26.3ms\n",
      "image 49/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_49.tif: 640x640 17 group_of_treess, 26.3ms\n",
      "image 50/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_50.tif: 640x640 2 group_of_treess, 26.5ms\n",
      "image 51/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_51.tif: 640x640 3 group_of_treess, 25.3ms\n",
      "image 52/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_52.tif: 640x640 9 group_of_treess, 115.4ms\n",
      "image 53/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_53.tif: 640x640 2 group_of_treess, 25.3ms\n",
      "image 54/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_54.tif: 640x640 2 group_of_treess, 25.1ms\n",
      "image 55/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_55.tif: 640x640 7 group_of_treess, 25.4ms\n",
      "image 56/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_56.tif: 640x640 16 group_of_treess, 25.4ms\n",
      "image 57/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_57.tif: 640x640 1 group_of_trees, 25.4ms\n",
      "image 58/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_58.tif: 640x640 (no detections), 42.5ms\n",
      "image 59/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_59.tif: 640x640 (no detections), 116.9ms\n",
      "image 60/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_60.tif: 640x640 1 group_of_trees, 48.8ms\n",
      "image 61/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_61.tif: 640x640 1 group_of_trees, 48.7ms\n",
      "image 62/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_62.tif: 640x640 (no detections), 48.3ms\n",
      "image 63/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_63.tif: 640x640 6 group_of_treess, 73.4ms\n",
      "image 64/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_64.tif: 640x640 5 group_of_treess, 60.0ms\n",
      "image 65/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_65.tif: 640x640 (no detections), 46.1ms\n",
      "image 66/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_66.tif: 640x640 1 group_of_trees, 46.0ms\n",
      "image 67/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_67.tif: 640x640 2 group_of_treess, 45.5ms\n",
      "image 68/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_68.tif: 640x640 (no detections), 47.4ms\n",
      "image 69/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_69.tif: 640x640 1 group_of_trees, 45.5ms\n",
      "image 70/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_70.tif: 640x640 5 group_of_treess, 13.3ms\n",
      "image 71/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_71.tif: 640x640 (no detections), 13.3ms\n",
      "image 72/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_72.tif: 640x640 11 group_of_treess, 13.3ms\n",
      "image 73/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_73.tif: 640x640 9 group_of_treess, 13.5ms\n",
      "image 74/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_74.tif: 640x640 3 group_of_treess, 13.3ms\n",
      "image 75/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\20cm_evaluation_75.tif: 640x640 3 group_of_treess, 13.5ms\n",
      "image 76/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_100.tif: 640x640 5 group_of_treess, 13.4ms\n",
      "image 77/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_76.tif: 640x640 (no detections), 13.3ms\n",
      "image 78/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_77.tif: 640x640 19 group_of_treess, 13.4ms\n",
      "image 79/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_78.tif: 640x640 18 group_of_treess, 13.2ms\n",
      "image 80/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_79.tif: 640x640 11 group_of_treess, 13.2ms\n",
      "image 81/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_80.tif: 640x640 30 group_of_treess, 13.4ms\n",
      "image 82/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_81.tif: 640x640 17 group_of_treess, 13.3ms\n",
      "image 83/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_82.tif: 640x640 8 group_of_treess, 13.5ms\n",
      "image 84/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_83.tif: 640x640 5 group_of_treess, 13.3ms\n",
      "image 85/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_84.tif: 640x640 7 group_of_treess, 13.4ms\n",
      "image 86/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_85.tif: 640x640 5 group_of_treess, 13.3ms\n",
      "image 87/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_86.tif: 640x640 3 group_of_treess, 13.4ms\n",
      "image 88/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_87.tif: 640x640 21 group_of_treess, 15.4ms\n",
      "image 89/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_88.tif: 640x640 12 group_of_treess, 15.8ms\n",
      "image 90/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_89.tif: 640x640 8 group_of_treess, 15.7ms\n",
      "image 91/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_90.tif: 640x640 13 group_of_treess, 16.2ms\n",
      "image 92/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_91.tif: 640x640 15 group_of_treess, 16.1ms\n",
      "image 93/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_92.tif: 640x640 19 group_of_treess, 16.4ms\n",
      "image 94/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_93.tif: 640x640 16 group_of_treess, 16.6ms\n",
      "image 95/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_94.tif: 640x640 12 group_of_treess, 17.0ms\n",
      "image 96/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_95.tif: 640x640 15 group_of_treess, 17.5ms\n",
      "image 97/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_96.tif: 640x640 7 group_of_treess, 17.3ms\n",
      "image 98/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_97.tif: 640x640 3 group_of_treess, 17.6ms\n",
      "image 99/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_98.tif: 640x640 11 group_of_treess, 17.6ms\n",
      "image 100/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\40cm_evaluation_99.tif: 640x640 15 group_of_treess, 18.1ms\n",
      "image 101/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_101.tif: 640x640 17 group_of_treess, 18.2ms\n",
      "image 102/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_102.tif: 640x640 86 group_of_treess, 18.7ms\n",
      "image 103/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_103.tif: 640x640 138 group_of_treess, 17.3ms\n",
      "image 104/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_104.tif: 640x640 23 group_of_treess, 12.0ms\n",
      "image 105/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_105.tif: 640x640 101 group_of_treess, 11.8ms\n",
      "image 106/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_106.tif: 640x640 61 group_of_treess, 11.9ms\n",
      "image 107/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_107.tif: 640x640 16 group_of_treess, 12.5ms\n",
      "image 108/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_108.tif: 640x640 16 group_of_treess, 11.9ms\n",
      "image 109/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_109.tif: 640x640 115 group_of_treess, 12.7ms\n",
      "image 110/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_110.tif: 640x640 16 group_of_treess, 12.3ms\n",
      "image 111/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_111.tif: 640x640 52 group_of_treess, 12.6ms\n",
      "image 112/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_112.tif: 640x640 87 group_of_treess, 14.9ms\n",
      "image 113/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_113.tif: 640x640 63 group_of_treess, 14.9ms\n",
      "image 114/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_114.tif: 640x640 63 group_of_treess, 16.0ms\n",
      "image 115/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_115.tif: 640x640 2 group_of_treess, 16.5ms\n",
      "image 116/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_116.tif: 640x640 14 group_of_treess, 16.5ms\n",
      "image 117/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_117.tif: 640x640 107 group_of_treess, 16.8ms\n",
      "image 118/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_118.tif: 640x640 88 group_of_treess, 17.8ms\n",
      "image 119/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_119.tif: 640x640 110 group_of_treess, 18.1ms\n",
      "image 120/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_120.tif: 640x640 78 group_of_treess, 19.0ms\n",
      "image 121/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_121.tif: 640x640 27 group_of_treess, 20.2ms\n",
      "image 122/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_122.tif: 640x640 40 group_of_treess, 20.6ms\n",
      "image 123/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_123.tif: 640x640 63 group_of_treess, 21.2ms\n",
      "image 124/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_124.tif: 640x640 74 group_of_treess, 21.5ms\n",
      "image 125/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\60cm_evaluation_125.tif: 640x640 29 group_of_treess, 21.6ms\n",
      "image 126/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_126.tif: 640x640 28 group_of_treess, 22.1ms\n",
      "image 127/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_127.tif: 640x640 8 group_of_treess, 22.6ms\n",
      "image 128/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_128.tif: 640x640 14 group_of_treess, 23.3ms\n",
      "image 129/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_129.tif: 640x640 23 group_of_treess, 23.6ms\n",
      "image 130/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_130.tif: 640x640 10 group_of_treess, 22.7ms\n",
      "image 131/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_131.tif: 640x640 11 group_of_treess, 22.7ms\n",
      "image 132/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_132.tif: 640x640 48 group_of_treess, 22.9ms\n",
      "image 133/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_133.tif: 640x640 13 group_of_treess, 22.3ms\n",
      "image 134/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_134.tif: 640x640 108 group_of_treess, 22.1ms\n",
      "image 135/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_135.tif: 640x640 6 group_of_treess, 17.9ms\n",
      "image 136/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_136.tif: 640x640 14 group_of_treess, 17.7ms\n",
      "image 137/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_137.tif: 640x640 23 group_of_treess, 17.6ms\n",
      "image 138/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_138.tif: 640x640 20 group_of_treess, 17.8ms\n",
      "image 139/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_139.tif: 640x640 14 group_of_treess, 17.7ms\n",
      "image 140/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_140.tif: 640x640 10 group_of_treess, 17.7ms\n",
      "image 141/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_141.tif: 640x640 12 group_of_treess, 17.6ms\n",
      "image 142/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_142.tif: 640x640 3 group_of_treess, 17.6ms\n",
      "image 143/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_143.tif: 640x640 100 group_of_treess, 17.7ms\n",
      "image 144/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_144.tif: 640x640 52 group_of_treess, 17.7ms\n",
      "image 145/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_145.tif: 640x640 22 group_of_treess, 18.3ms\n",
      "image 146/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_146.tif: 640x640 66 group_of_treess, 19.6ms\n",
      "image 147/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_147.tif: 640x640 53 group_of_treess, 18.0ms\n",
      "image 148/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_148.tif: 640x640 21 group_of_treess, 18.0ms\n",
      "image 149/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_149.tif: 640x640 35 group_of_treess, 17.9ms\n",
      "image 150/150 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\test\\evaluation_images\\80cm_evaluation_150.tif: 640x640 65 group_of_treess, 18.0ms\n",
      "Speed: 7.0ms preprocess, 33.7ms inference, 17.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\predict\\submission_run2\u001b[0m\n",
      "131 labels saved to C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\runs\\predict\\submission_run2\\labels\n",
      "Predictions saved to: runs/predict/submission_run\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Path to the best model weights from your training run\n",
    "MODEL_WEIGHTS_PATH = \"runs/train/tree_canopy_experiment_1/weights/best.pt\" \n",
    "# Path to the directory with test images\n",
    "TEST_IMAGES_DIR = \"data/test/evaluation_images\" \n",
    "# Directory to save prediction results\n",
    "PREDICTION_SAVE_DIR = \"runs/predict/submission_run\"\n",
    "\n",
    "def predict():\n",
    "    # Load the trained model\n",
    "    model = YOLO(MODEL_WEIGHTS_PATH)\n",
    "\n",
    "    # Run inference on the test images\n",
    "    print(f\"Running prediction on images in: {TEST_IMAGES_DIR}\")\n",
    "    results = model.predict(\n",
    "        source=TEST_IMAGES_DIR,\n",
    "        save=True,          # Save images with predictions\n",
    "        save_txt=True,      # Save results in.txt files (YOLO format)\n",
    "        conf=0.25,          # Confidence threshold for detection\n",
    "        project=\"runs/predict\",\n",
    "        name=\"submission_run\"\n",
    "    )\n",
    "    print(f\"Predictions saved to: {PREDICTION_SAVE_DIR}\")\n",
    "    return results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aee34e0d-3a5a-4116-b503-11044e576119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading predictions from: runs\\predict\\submission_run\\labels\n",
      "10cm_evaluation_1.tif: 6 objects processed\n",
      "10cm_evaluation_10.tif: 13 objects processed\n",
      "10cm_evaluation_11.tif: 7 objects processed\n",
      "10cm_evaluation_12.tif: 18 objects processed\n",
      "10cm_evaluation_14.tif: 4 objects processed\n",
      "10cm_evaluation_16.tif: 2 objects processed\n",
      "10cm_evaluation_17.tif: 14 objects processed\n",
      "10cm_evaluation_18.tif: 3 objects processed\n",
      "10cm_evaluation_2.tif: 1 objects processed\n",
      "10cm_evaluation_21.tif: 1 objects processed\n",
      "10cm_evaluation_22.tif: 3 objects processed\n",
      "10cm_evaluation_23.tif: 3 objects processed\n",
      "10cm_evaluation_25.tif: 1 objects processed\n",
      "10cm_evaluation_26.tif: 2 objects processed\n",
      "10cm_evaluation_28.tif: 2 objects processed\n",
      "10cm_evaluation_29.tif: 6 objects processed\n",
      "10cm_evaluation_3.tif: 1 objects processed\n",
      "10cm_evaluation_30.tif: 9 objects processed\n",
      "10cm_evaluation_31.tif: 3 objects processed\n",
      "10cm_evaluation_32.tif: 16 objects processed\n",
      "10cm_evaluation_33.tif: 1 objects processed\n",
      "10cm_evaluation_34.tif: 5 objects processed\n",
      "10cm_evaluation_36.tif: 1 objects processed\n",
      "10cm_evaluation_4.tif: 9 objects processed\n",
      "10cm_evaluation_5.tif: 6 objects processed\n",
      "10cm_evaluation_6.tif: 3 objects processed\n",
      "10cm_evaluation_8.tif: 8 objects processed\n",
      "10cm_evaluation_9.tif: 15 objects processed\n",
      "20cm_evaluation_39.tif: 24 objects processed\n",
      "20cm_evaluation_40.tif: 5 objects processed\n",
      "20cm_evaluation_41.tif: 15 objects processed\n",
      "20cm_evaluation_43.tif: 6 objects processed\n",
      "20cm_evaluation_44.tif: 3 objects processed\n",
      "20cm_evaluation_45.tif: 8 objects processed\n",
      "20cm_evaluation_47.tif: 6 objects processed\n",
      "20cm_evaluation_48.tif: 5 objects processed\n",
      "20cm_evaluation_49.tif: 17 objects processed\n",
      "20cm_evaluation_50.tif: 2 objects processed\n",
      "20cm_evaluation_51.tif: 3 objects processed\n",
      "20cm_evaluation_52.tif: 9 objects processed\n",
      "20cm_evaluation_53.tif: 2 objects processed\n",
      "20cm_evaluation_54.tif: 2 objects processed\n",
      "20cm_evaluation_55.tif: 7 objects processed\n",
      "20cm_evaluation_56.tif: 16 objects processed\n",
      "20cm_evaluation_57.tif: 1 objects processed\n",
      "20cm_evaluation_60.tif: 1 objects processed\n",
      "20cm_evaluation_61.tif: 1 objects processed\n",
      "20cm_evaluation_63.tif: 6 objects processed\n",
      "20cm_evaluation_64.tif: 5 objects processed\n",
      "20cm_evaluation_66.tif: 1 objects processed\n",
      "20cm_evaluation_67.tif: 2 objects processed\n",
      "20cm_evaluation_69.tif: 1 objects processed\n",
      "20cm_evaluation_70.tif: 5 objects processed\n",
      "20cm_evaluation_72.tif: 11 objects processed\n",
      "20cm_evaluation_73.tif: 9 objects processed\n",
      "20cm_evaluation_74.tif: 3 objects processed\n",
      "20cm_evaluation_75.tif: 3 objects processed\n",
      "40cm_evaluation_100.tif: 5 objects processed\n",
      "40cm_evaluation_77.tif: 19 objects processed\n",
      "40cm_evaluation_78.tif: 18 objects processed\n",
      "40cm_evaluation_79.tif: 11 objects processed\n",
      "40cm_evaluation_80.tif: 30 objects processed\n",
      "40cm_evaluation_81.tif: 17 objects processed\n",
      "40cm_evaluation_82.tif: 8 objects processed\n",
      "40cm_evaluation_83.tif: 5 objects processed\n",
      "40cm_evaluation_84.tif: 7 objects processed\n",
      "40cm_evaluation_85.tif: 5 objects processed\n",
      "40cm_evaluation_86.tif: 3 objects processed\n",
      "40cm_evaluation_87.tif: 21 objects processed\n",
      "40cm_evaluation_88.tif: 12 objects processed\n",
      "40cm_evaluation_89.tif: 8 objects processed\n",
      "40cm_evaluation_90.tif: 13 objects processed\n",
      "40cm_evaluation_91.tif: 15 objects processed\n",
      "40cm_evaluation_92.tif: 19 objects processed\n",
      "40cm_evaluation_93.tif: 16 objects processed\n",
      "40cm_evaluation_94.tif: 12 objects processed\n",
      "40cm_evaluation_95.tif: 15 objects processed\n",
      "40cm_evaluation_96.tif: 7 objects processed\n",
      "40cm_evaluation_97.tif: 3 objects processed\n",
      "40cm_evaluation_98.tif: 11 objects processed\n",
      "40cm_evaluation_99.tif: 15 objects processed\n",
      "60cm_evaluation_101.tif: 17 objects processed\n",
      "60cm_evaluation_102.tif: 86 objects processed\n",
      "60cm_evaluation_103.tif: 138 objects processed\n",
      "60cm_evaluation_104.tif: 23 objects processed\n",
      "60cm_evaluation_105.tif: 101 objects processed\n",
      "60cm_evaluation_106.tif: 61 objects processed\n",
      "60cm_evaluation_107.tif: 16 objects processed\n",
      "60cm_evaluation_108.tif: 16 objects processed\n",
      "60cm_evaluation_109.tif: 115 objects processed\n",
      "60cm_evaluation_110.tif: 16 objects processed\n",
      "60cm_evaluation_111.tif: 52 objects processed\n",
      "60cm_evaluation_112.tif: 87 objects processed\n",
      "60cm_evaluation_113.tif: 63 objects processed\n",
      "60cm_evaluation_114.tif: 63 objects processed\n",
      "60cm_evaluation_115.tif: 2 objects processed\n",
      "60cm_evaluation_116.tif: 14 objects processed\n",
      "60cm_evaluation_117.tif: 107 objects processed\n",
      "60cm_evaluation_118.tif: 88 objects processed\n",
      "60cm_evaluation_119.tif: 110 objects processed\n",
      "60cm_evaluation_120.tif: 78 objects processed\n",
      "60cm_evaluation_121.tif: 27 objects processed\n",
      "60cm_evaluation_122.tif: 40 objects processed\n",
      "60cm_evaluation_123.tif: 63 objects processed\n",
      "60cm_evaluation_124.tif: 74 objects processed\n",
      "60cm_evaluation_125.tif: 29 objects processed\n",
      "80cm_evaluation_126.tif: 28 objects processed\n",
      "80cm_evaluation_127.tif: 8 objects processed\n",
      "80cm_evaluation_128.tif: 14 objects processed\n",
      "80cm_evaluation_129.tif: 23 objects processed\n",
      "80cm_evaluation_130.tif: 10 objects processed\n",
      "80cm_evaluation_131.tif: 11 objects processed\n",
      "80cm_evaluation_132.tif: 48 objects processed\n",
      "80cm_evaluation_133.tif: 13 objects processed\n",
      "80cm_evaluation_134.tif: 108 objects processed\n",
      "80cm_evaluation_135.tif: 6 objects processed\n",
      "80cm_evaluation_136.tif: 14 objects processed\n",
      "80cm_evaluation_137.tif: 23 objects processed\n",
      "80cm_evaluation_138.tif: 20 objects processed\n",
      "80cm_evaluation_139.tif: 14 objects processed\n",
      "80cm_evaluation_140.tif: 10 objects processed\n",
      "80cm_evaluation_141.tif: 12 objects processed\n",
      "80cm_evaluation_142.tif: 3 objects processed\n",
      "80cm_evaluation_143.tif: 100 objects processed\n",
      "80cm_evaluation_144.tif: 52 objects processed\n",
      "80cm_evaluation_145.tif: 22 objects processed\n",
      "80cm_evaluation_146.tif: 66 objects processed\n",
      "80cm_evaluation_147.tif: 53 objects processed\n",
      "80cm_evaluation_148.tif: 21 objects processed\n",
      "80cm_evaluation_149.tif: 35 objects processed\n",
      "80cm_evaluation_150.tif: 65 objects processed\n",
      "\n",
      "Submission file created at: data\\test\\evaluation_images\\jsons\\yolo_submission.json\n",
      "Total images processed: 131\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "PREDICTION_LABELS_DIR = Path(\"runs/predict/submission_run/labels\")  # YOLO .txt output\n",
    "TEST_IMAGES_DIR = Path(\"data/test/evaluation_images\")               # Original images\n",
    "SUBMISSION_FILE_PATH = Path(\"data/test/evaluation_images/jsons/yolo_submission.json\")\n",
    "\n",
    "# Map YOLO class indices to names (must match your training class_map)\n",
    "CLASS_MAP = {\n",
    "    0: \"group_of_trees\",\n",
    "    1: \"individual_tree\"\n",
    "}\n",
    "\n",
    "DEBUG = True  # Set False to disable prints\n",
    "\n",
    "def create_submission_file():\n",
    "    submission_data = {\"images\": []}\n",
    "\n",
    "    print(f\"Reading predictions from: {PREDICTION_LABELS_DIR}\")\n",
    "    \n",
    "    for label_file in PREDICTION_LABELS_DIR.glob(\"*.txt\"):\n",
    "        image_name = f\"{label_file.stem}.tif\"  # adjust extension if needed\n",
    "        image_path = TEST_IMAGES_DIR / image_name\n",
    "        \n",
    "        if not image_path.exists():\n",
    "            print(f\"Warning: Image {image_name} not found in {TEST_IMAGES_DIR}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        with Image.open(image_path) as img:\n",
    "            img_w, img_h = img.size\n",
    "\n",
    "        annotations = []\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 3:  # class + at least 1 point\n",
    "                continue\n",
    "            class_id = int(parts[0])\n",
    "            norm_coords = [float(p) for p in parts[1:]]\n",
    "            coords = []\n",
    "            for i in range(0, len(norm_coords), 2):\n",
    "                x = norm_coords[i] * img_w\n",
    "                y = norm_coords[i+1] * img_h\n",
    "                coords.append([x, y])\n",
    "            coords = np.array(coords, dtype=np.float32)\n",
    "\n",
    "            if len(coords) < 3:\n",
    "                continue  # skip too small polygons\n",
    "\n",
    "            # Compute minimum bounding rectangle (4 points)\n",
    "            rect = cv2.minAreaRect(coords)\n",
    "            box_pts = cv2.boxPoints(rect)  # 4 points\n",
    "            box_pts = box_pts.flatten().tolist()  # 8 numbers\n",
    "\n",
    "            annotations.append({\n",
    "                \"class\": CLASS_MAP.get(class_id, \"unknown\"),\n",
    "                \"confidence_score\": 1.0,  # YOLOv8-seg does not save confidence in .txt\n",
    "                \"segmentation\": [float(round(c)) for c in box_pts]\n",
    "            })\n",
    "\n",
    "        submission_data[\"images\"].append({\n",
    "            \"file_name\": image_name,\n",
    "            \"width\": img_w,\n",
    "            \"height\": img_h,\n",
    "            \"cm_resolution\": 10,   # adjust if needed\n",
    "            \"scene_type\": \"unknown\",\n",
    "            \"annotations\": annotations\n",
    "        })\n",
    "\n",
    "        if DEBUG:\n",
    "            print(f\"{image_name}: {len(annotations)} objects processed\")\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    SUBMISSION_FILE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(SUBMISSION_FILE_PATH, 'w') as f:\n",
    "        json.dump(submission_data, f, indent=4)\n",
    "\n",
    "    print(f\"\\nSubmission file created at: {SUBMISSION_FILE_PATH}\")\n",
    "    print(f\"Total images processed: {len(submission_data['images'])}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_submission_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e28d58d2-e217-4563-9dc6-a2871928bd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\hmanasi1\\Documents\\ADML\\Project\\data\\raw\\train_images\\10cm_train_3.tif: 640x640 2 group_of_treess, 12.5ms\n",
      "Speed: 9.0ms preprocess, 12.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "YOLO prediction saved to: data\\raw\\train_images\\jsons\\yolo_train_image_predictions.json\n",
      "YOLO polygons: 2\n"
     ]
    }
   ],
   "source": [
    "# Notebook: yolo_train_image_prediction.ipynb\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- CONFIG ---\n",
    "TRAIN_IMAGE = Path(\"data/raw/train_images/10cm_train_3.tif\")\n",
    "OUTPUT_JSON_PATH = Path(\"data/raw/train_images/jsons/yolo_train_image_predictions.json\")\n",
    "YOLO_MODEL_PATH = \"runs/train/tree_canopy_experiment_1/weights/best.pt\"\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "CLASSES = [\"group_of_trees\", \"individual_tree\"]  # match your YOLO training\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ------------------------------\n",
    "# Helper: Convert mask to polygons\n",
    "# ------------------------------\n",
    "def mask_to_polygons(mask, min_area=10):\n",
    "    polygons_with_scores = []\n",
    "    mask_uint8 = (mask > 0.5).astype(np.uint8) * 255\n",
    "    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) >= min_area:\n",
    "            poly = Polygon(cnt[:,0,:])\n",
    "            polygons_with_scores.append((poly, 1.0))  # YOLO mask has implicit confidence\n",
    "    return polygons_with_scores\n",
    "\n",
    "# ------------------------------\n",
    "# Load YOLO model\n",
    "# ------------------------------\n",
    "model_yolo = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "# ------------------------------\n",
    "# Run prediction\n",
    "# ------------------------------\n",
    "results = model_yolo.predict(\n",
    "    source=str(TRAIN_IMAGE),\n",
    "    conf=CONFIDENCE_THRESHOLD,\n",
    "    save=False,\n",
    "    save_txt=False,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "yolo_annotations = []\n",
    "for r in results:\n",
    "    # r.boxes.cls contains class IDs for each detected object\n",
    "    class_ids = r.boxes.cls.cpu().numpy()\n",
    "    \n",
    "    if hasattr(r, \"masks\") and r.masks is not None:\n",
    "        masks = r.masks.data.cpu().numpy()  # [N, H, W]\n",
    "        for i, mask in enumerate(masks):\n",
    "            class_name = CLASSES[int(class_ids[i])]\n",
    "            polys = mask_to_polygons(mask)\n",
    "            for poly, score in polys:\n",
    "                coords = np.array(poly.exterior.coords).flatten().tolist()\n",
    "                yolo_annotations.append({\n",
    "                    \"class\": class_name,\n",
    "                    \"confidence_score\": float(score),\n",
    "                    \"segmentation\": [float(c) for c in coords]\n",
    "                })\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Save JSON\n",
    "# ------------------------------\n",
    "image_np = np.array(Image.open(TRAIN_IMAGE))\n",
    "output_json = {\n",
    "    \"file_name\": TRAIN_IMAGE.name,\n",
    "    \"width\": image_np.shape[1],\n",
    "    \"height\": image_np.shape[0],\n",
    "    \"cm_resolution\": 10,\n",
    "    \"scene_type\": \"unknown\",\n",
    "    \"annotations_yolo\": yolo_annotations\n",
    "}\n",
    "\n",
    "OUTPUT_JSON_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUTPUT_JSON_PATH, 'w') as f:\n",
    "    json.dump(output_json, f, indent=4)\n",
    "\n",
    "print(f\"YOLO prediction saved to: {OUTPUT_JSON_PATH}\")\n",
    "print(f\"YOLO polygons: {len(yolo_annotations)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0eda4a-4596-4072-b3a3-2fa8218ca880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py311 GPU",
   "language": "python",
   "name": "py311_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4a9468-334f-4f06-bc71-a111476a8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (8.3.217)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pycocotools in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (3.10.7)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (1.16.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (2.0.1+cu117)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (0.15.2+cu117)\n",
      "Requirement already satisfied: psutil in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (7.1.1)\n",
      "Requirement already satisfied: polars in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (1.34.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: polars-runtime-32==1.34.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from polars->ultralytics) (1.34.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics opencv-python numpy pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f069305d-2c90-4a61-a7a8-9365d4021b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segmentation-models-pytorch in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: torch in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (2.0.1+cu117)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (0.15.2+cu117)\n",
      "Requirement already satisfied: albumentations in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from segmentation-models-pytorch) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from segmentation-models-pytorch) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from segmentation-models-pytorch) (11.3.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from segmentation-models-pytorch) (0.6.2)\n",
      "Requirement already satisfied: timm>=0.9 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from segmentation-models-pytorch) (1.0.20)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from segmentation-models-pytorch) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from torchvision) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from albumentations) (1.16.2)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from albumentations) (0.25.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from albumentations) (6.0.3)\n",
      "Requirement already satisfied: qudida>=0.0.4 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from albumentations) (4.9.0.80)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.7.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2025.10.16)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from tqdm>=4.42.1->segmentation-models-pytorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: geopandas in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: rasterio in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from geopandas) (0.11.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from geopandas) (25.0)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from geopandas) (2.3.3)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from geopandas) (3.7.2)\n",
      "Requirement already satisfied: shapely>=2.0.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from geopandas) (2.1.2)\n",
      "Requirement already satisfied: affine in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from rasterio) (25.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from rasterio) (2022.12.7)\n",
      "Requirement already satisfied: click>=4.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from rasterio) (8.3.0)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: click-plugins in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from rasterio) (1.1.1.2)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from rasterio) (3.2.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from click>=4.0->rasterio) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hmanasi1\\.conda\\envs\\adml_py311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install segmentation-models-pytorch torch torchvision albumentations\n",
    "!pip install geopandas rasterio scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ac2a52-f914-4ed5-948b-f8dabb48325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d19a66f-4269-412e-a56d-4b15f083b576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and saving multi-channel masks...\n",
      "Images saved to: data\\processed_unet\\images\n",
      "Masks saved to: data\\processed_unet\\masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hmanasi1\\.conda\\envs\\adml_py311\\Lib\\site-packages\\segmentation_models_pytorch\\base\\modules.py:182: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.5719, Val Loss: 0.4955\n",
      "   -> Best model saved!\n",
      "Epoch 2/50, Train Loss: 0.4638, Val Loss: 0.4373\n",
      "   -> Best model saved!\n",
      "Epoch 3/50, Train Loss: 0.4304, Val Loss: 0.4223\n",
      "   -> Best model saved!\n",
      "Epoch 4/50, Train Loss: 0.4158, Val Loss: 0.3986\n",
      "   -> Best model saved!\n",
      "Epoch 5/50, Train Loss: 0.4073, Val Loss: 0.3891\n",
      "   -> Best model saved!\n",
      "Epoch 6/50, Train Loss: 0.3959, Val Loss: 0.3829\n",
      "   -> Best model saved!\n",
      "Epoch 7/50, Train Loss: 0.3885, Val Loss: 0.3899\n",
      "Epoch 8/50, Train Loss: 0.3862, Val Loss: 0.3830\n",
      "Epoch 9/50, Train Loss: 0.3850, Val Loss: 0.3775\n",
      "   -> Best model saved!\n",
      "Epoch 10/50, Train Loss: 0.3863, Val Loss: 0.3789\n",
      "Epoch 11/50, Train Loss: 0.3802, Val Loss: 0.3811\n",
      "Epoch 12/50, Train Loss: 0.3789, Val Loss: 0.3863\n",
      "Epoch 13/50, Train Loss: 0.3795, Val Loss: 0.3717\n",
      "   -> Best model saved!\n",
      "Epoch 14/50, Train Loss: 0.3739, Val Loss: 0.3720\n",
      "Epoch 15/50, Train Loss: 0.3713, Val Loss: 0.3873\n",
      "Epoch 16/50, Train Loss: 0.3772, Val Loss: 0.3748\n",
      "Epoch 17/50, Train Loss: 0.3687, Val Loss: 0.3675\n",
      "   -> Best model saved!\n",
      "Epoch 18/50, Train Loss: 0.3697, Val Loss: 0.3640\n",
      "   -> Best model saved!\n",
      "Epoch 19/50, Train Loss: 0.3707, Val Loss: 0.3671\n",
      "Epoch 20/50, Train Loss: 0.3659, Val Loss: 0.3803\n",
      "Epoch 21/50, Train Loss: 0.3681, Val Loss: 0.3672\n",
      "Epoch 22/50, Train Loss: 0.3634, Val Loss: 0.3663\n",
      "Epoch 23/50, Train Loss: 0.3622, Val Loss: 0.3639\n",
      "   -> Best model saved!\n",
      "Epoch 24/50, Train Loss: 0.3618, Val Loss: 0.3695\n",
      "Epoch 25/50, Train Loss: 0.3600, Val Loss: 0.3639\n",
      "   -> Best model saved!\n",
      "Epoch 26/50, Train Loss: 0.3584, Val Loss: 0.3696\n",
      "Epoch 27/50, Train Loss: 0.3583, Val Loss: 0.3636\n",
      "   -> Best model saved!\n",
      "Epoch 28/50, Train Loss: 0.3574, Val Loss: 0.3680\n",
      "Epoch 29/50, Train Loss: 0.3591, Val Loss: 0.3684\n",
      "Epoch 30/50, Train Loss: 0.3637, Val Loss: 0.3669\n",
      "Epoch 31/50, Train Loss: 0.3574, Val Loss: 0.3653\n",
      "Epoch 32/50, Train Loss: 0.3545, Val Loss: 0.3662\n",
      "Epoch 33/50, Train Loss: 0.3557, Val Loss: 0.3651\n",
      "Epoch 34/50, Train Loss: 0.3568, Val Loss: 0.3659\n",
      "Epoch 35/50, Train Loss: 0.3551, Val Loss: 0.3661\n",
      "Epoch 36/50, Train Loss: 0.3545, Val Loss: 0.3630\n",
      "   -> Best model saved!\n",
      "Epoch 37/50, Train Loss: 0.3539, Val Loss: 0.3676\n",
      "Epoch 38/50, Train Loss: 0.3556, Val Loss: 0.3652\n",
      "Epoch 39/50, Train Loss: 0.3596, Val Loss: 0.3902\n",
      "Epoch 40/50, Train Loss: 0.3579, Val Loss: 0.3599\n",
      "   -> Best model saved!\n",
      "Epoch 41/50, Train Loss: 0.3622, Val Loss: 0.3731\n",
      "Epoch 42/50, Train Loss: 0.3549, Val Loss: 0.3588\n",
      "   -> Best model saved!\n",
      "Epoch 43/50, Train Loss: 0.3649, Val Loss: 0.3693\n",
      "Epoch 44/50, Train Loss: 0.3569, Val Loss: 0.3672\n",
      "Epoch 45/50, Train Loss: 0.3533, Val Loss: 0.3648\n",
      "Epoch 46/50, Train Loss: 0.3531, Val Loss: 0.3644\n",
      "Epoch 47/50, Train Loss: 0.3539, Val Loss: 0.3645\n",
      "Epoch 48/50, Train Loss: 0.3550, Val Loss: 0.3675\n",
      "Epoch 49/50, Train Loss: 0.3615, Val Loss: 0.3814\n",
      "Epoch 50/50, Train Loss: 0.3582, Val Loss: 0.3623\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 191\u001b[39m\n\u001b[32m    189\u001b[39m prepare_data()\n\u001b[32m    190\u001b[39m model = train_model()\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/test/evaluation_images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 232\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, eval_dir)\u001b[39m\n\u001b[32m    230\u001b[39m         out_json_path = img_path.parent / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path.stem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_pred.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_json_path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m             \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluation complete. JSON files saved for all evaluation images.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\adml_py311\\Lib\\json\\__init__.py:180\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     fp.write(chunk)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from rasterio import features\n",
    "import rasterio\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from skimage import measure\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "RAW_DATA_DIR = Path(\"data/raw\")\n",
    "PROCESSED_DATA_DIR = Path(\"data/processed_unet\")\n",
    "SOLAFUNE_JSON_PATH = RAW_DATA_DIR / \"train_annotations.json\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ENCODER = 'resnet18'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 2\n",
    "CLASSES = [\"individual_tree\", \"group_of_trees\"]  # Multi-class\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "# ------------------------\n",
    "# 1. DATA PREPARATION\n",
    "# ------------------------\n",
    "def parse_solafune_json_for_polygons(json_path):\n",
    "    annotations = {}\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for image_data in data.get('images', []):\n",
    "        filename = image_data['file_name']\n",
    "        width, height = image_data['width'], image_data['height']\n",
    "        annotations[filename] = {'size': (width, height), 'polygons': []}\n",
    "        for ann in image_data.get('annotations', []):\n",
    "            flat_points = ann['segmentation']\n",
    "            points = list(zip(flat_points[::2], flat_points[1::2]))\n",
    "            class_name = ann.get('class', 'group_of_trees')\n",
    "            if len(points) >= 3:\n",
    "                annotations[filename]['polygons'].append({'polygon': Polygon(points), 'class': class_name})\n",
    "    return annotations\n",
    "\n",
    "def create_and_save_masks(all_annotations, raw_image_dir, output_dir):\n",
    "    print(\"Creating and saving multi-channel masks...\")\n",
    "    images_out_dir = output_dir / \"images\"\n",
    "    masks_out_dir = output_dir / \"masks\"\n",
    "    images_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    masks_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for filename, data in all_annotations.items():\n",
    "        shutil.copy(raw_image_dir / filename, images_out_dir / filename)\n",
    "        width, height = data['size']\n",
    "\n",
    "        mask_array = np.zeros((NUM_CLASSES, height, width), dtype=np.uint8)\n",
    "        for ann in data['polygons']:\n",
    "            poly, cls_name = ann['polygon'], ann['class']\n",
    "            if cls_name in CLASSES:\n",
    "                cls_idx = CLASSES.index(cls_name)\n",
    "                mask_array[cls_idx] = np.maximum(mask_array[cls_idx],\n",
    "                                                 features.rasterize([poly], out_shape=(height, width),\n",
    "                                                                    transform=rasterio.Affine.identity(),\n",
    "                                                                    fill=0, all_touched=True, dtype=np.uint8))\n",
    "        # Save masks as multi-channel npy\n",
    "        np.save(masks_out_dir / f\"{Path(filename).stem}.npy\", mask_array)\n",
    "\n",
    "def prepare_data():\n",
    "    raw_image_dir = RAW_DATA_DIR / \"train_images\"\n",
    "    all_annotations = parse_solafune_json_for_polygons(SOLAFUNE_JSON_PATH)\n",
    "    create_and_save_masks(all_annotations, raw_image_dir, PROCESSED_DATA_DIR)\n",
    "    print(f\"Images saved to: {PROCESSED_DATA_DIR / 'images'}\")\n",
    "    print(f\"Masks saved to: {PROCESSED_DATA_DIR / 'masks'}\")\n",
    "\n",
    "# ------------------------\n",
    "# 2. DATASET\n",
    "# ------------------------\n",
    "class TreeCanopyDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "        mask = np.load(self.mask_paths[idx])  # shape: [num_classes, H, W]\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask.transpose(1,2,0))\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask'].permute(2,0,1).float()  # back to [C,H,W]\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# ------------------------\n",
    "# 3. AUGMENTATIONS\n",
    "# ------------------------\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 4. TRAINING\n",
    "# ------------------------\n",
    "def train_model():\n",
    "    data_dir = PROCESSED_DATA_DIR\n",
    "    all_image_paths = sorted(list((data_dir / \"images\").glob(\"*.*\")))\n",
    "    all_mask_paths = sorted(list((data_dir / \"masks\").glob(\"*.npy\")))\n",
    "\n",
    "    train_imgs, val_imgs, train_msks, val_msks = train_test_split(\n",
    "        all_image_paths, all_mask_paths, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = TreeCanopyDataset(train_imgs, train_msks, transform=train_transform)\n",
    "    val_dataset = TreeCanopyDataset(val_imgs, val_msks, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = smp.Unet(encoder_name=ENCODER, encoder_weights=ENCODER_WEIGHTS,\n",
    "                     in_channels=3, classes=NUM_CLASSES, activation='softmax').to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                # targets for CELoss: shape [B,H,W], values: 0..C-1\n",
    "                targets = masks.argmax(dim=1).long()\n",
    "                loss = criterion(outputs, targets)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad(), autocast():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                targets = masks.argmax(dim=1).long()\n",
    "                val_loss += criterion(outputs, targets).item()\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_unet_model_multiclass.pth\")\n",
    "            print(\"   -> Best model saved!\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# ------------------------\n",
    "# 5. RUN EVERYTHING\n",
    "# ------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_data()\n",
    "    model = train_model()\n",
    "    evaluate_model(model, Path(\"data/test/evaluation_images\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d89bbf89-450c-4a1e-a938-f7b63d7a71d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:   1%|▉                                                                         | 2/150 [00:00<00:42,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_1.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_1.tif - Class 'group_of_trees' - 3 polygons detected\n",
      "10cm_evaluation_10.tif - Class 'individual_tree' - 2 polygons detected\n",
      "10cm_evaluation_10.tif - Class 'group_of_trees' - 15 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:   2%|█▍                                                                        | 3/150 [00:00<00:30,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_11.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_11.tif - Class 'group_of_trees' - 16 polygons detected\n",
      "10cm_evaluation_12.tif - Class 'individual_tree' - 2 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:   3%|██▍                                                                       | 5/150 [00:01<00:25,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_12.tif - Class 'group_of_trees' - 30 polygons detected\n",
      "10cm_evaluation_13.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_13.tif - Class 'group_of_trees' - 0 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:   4%|██▉                                                                       | 6/150 [00:01<00:28,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_14.tif - Class 'individual_tree' - 18 polygons detected\n",
      "10cm_evaluation_14.tif - Class 'group_of_trees' - 42 polygons detected\n",
      "10cm_evaluation_15.tif - Class 'individual_tree' - 3 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:   5%|███▉                                                                      | 8/150 [00:01<00:25,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_15.tif - Class 'group_of_trees' - 33 polygons detected\n",
      "10cm_evaluation_16.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_16.tif - Class 'group_of_trees' - 13 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:   7%|████▊                                                                    | 10/150 [00:01<00:23,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_17.tif - Class 'individual_tree' - 8 polygons detected\n",
      "10cm_evaluation_17.tif - Class 'group_of_trees' - 27 polygons detected\n",
      "10cm_evaluation_18.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_18.tif - Class 'group_of_trees' - 8 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:   8%|█████▊                                                                   | 12/150 [00:02<00:21,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_19.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_19.tif - Class 'group_of_trees' - 2 polygons detected\n",
      "10cm_evaluation_2.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_2.tif - Class 'group_of_trees' - 2 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:   9%|██████▊                                                                  | 14/150 [00:02<00:19,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_20.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_20.tif - Class 'group_of_trees' - 2 polygons detected\n",
      "10cm_evaluation_21.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_21.tif - Class 'group_of_trees' - 5 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  11%|███████▊                                                                 | 16/150 [00:02<00:18,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_22.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_22.tif - Class 'group_of_trees' - 12 polygons detected\n",
      "10cm_evaluation_23.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_23.tif - Class 'group_of_trees' - 2 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  11%|████████▎                                                                | 17/150 [00:02<00:19,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_24.tif - Class 'individual_tree' - 2 polygons detected\n",
      "10cm_evaluation_24.tif - Class 'group_of_trees' - 27 polygons detected\n",
      "10cm_evaluation_25.tif - Class 'individual_tree' - 3 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  13%|█████████▏                                                               | 19/150 [00:03<00:19,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_25.tif - Class 'group_of_trees' - 29 polygons detected\n",
      "10cm_evaluation_26.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_26.tif - Class 'group_of_trees' - 22 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  14%|██████████▏                                                              | 21/150 [00:03<00:18,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_27.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_27.tif - Class 'group_of_trees' - 25 polygons detected\n",
      "10cm_evaluation_28.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_28.tif - Class 'group_of_trees' - 11 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  15%|███████████▏                                                             | 23/150 [00:03<00:17,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_29.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_29.tif - Class 'group_of_trees' - 4 polygons detected\n",
      "10cm_evaluation_3.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_3.tif - Class 'group_of_trees' - 2 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  17%|████████████▏                                                            | 25/150 [00:04<00:16,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_30.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_30.tif - Class 'group_of_trees' - 8 polygons detected\n",
      "10cm_evaluation_31.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_31.tif - Class 'group_of_trees' - 5 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  18%|█████████████▏                                                           | 27/150 [00:04<00:23,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_32.tif - Class 'individual_tree' - 40 polygons detected\n",
      "10cm_evaluation_32.tif - Class 'group_of_trees' - 16 polygons detected\n",
      "10cm_evaluation_33.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_33.tif - Class 'group_of_trees' - 17 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  19%|█████████████▋                                                           | 28/150 [00:04<00:21,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_34.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_34.tif - Class 'group_of_trees' - 22 polygons detected\n",
      "10cm_evaluation_35.tif - Class 'individual_tree' - 93 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  20%|██████████████▌                                                          | 30/150 [00:05<00:40,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_35.tif - Class 'group_of_trees' - 157 polygons detected\n",
      "10cm_evaluation_36.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_36.tif - Class 'group_of_trees' - 0 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  21%|███████████████▌                                                         | 32/150 [00:06<00:26,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_37.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_37.tif - Class 'group_of_trees' - 0 polygons detected\n",
      "10cm_evaluation_38.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_38.tif - Class 'group_of_trees' - 0 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  23%|████████████████▌                                                        | 34/150 [00:06<00:19,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_4.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_4.tif - Class 'group_of_trees' - 14 polygons detected\n",
      "10cm_evaluation_5.tif - Class 'individual_tree' - 2 polygons detected\n",
      "10cm_evaluation_5.tif - Class 'group_of_trees' - 5 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  24%|█████████████████▌                                                       | 36/150 [00:06<00:16,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_6.tif - Class 'individual_tree' - 2 polygons detected\n",
      "10cm_evaluation_6.tif - Class 'group_of_trees' - 18 polygons detected\n",
      "10cm_evaluation_7.tif - Class 'individual_tree' - 1 polygons detected\n",
      "10cm_evaluation_7.tif - Class 'group_of_trees' - 3 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  25%|██████████████████                                                       | 37/150 [00:06<00:19,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_8.tif - Class 'individual_tree' - 15 polygons detected\n",
      "10cm_evaluation_8.tif - Class 'group_of_trees' - 16 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  26%|██████████████████▉                                                      | 39/150 [00:07<00:17,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10cm_evaluation_9.tif - Class 'individual_tree' - 9 polygons detected\n",
      "10cm_evaluation_9.tif - Class 'group_of_trees' - 13 polygons detected\n",
      "20cm_evaluation_39.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_39.tif - Class 'group_of_trees' - 4 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  27%|███████████████████▉                                                     | 41/150 [00:07<00:15,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_40.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_40.tif - Class 'group_of_trees' - 0 polygons detected\n",
      "20cm_evaluation_41.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_41.tif - Class 'group_of_trees' - 4 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  29%|████████████████████▉                                                    | 43/150 [00:07<00:14,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_42.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_42.tif - Class 'group_of_trees' - 5 polygons detected\n",
      "20cm_evaluation_43.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_43.tif - Class 'group_of_trees' - 12 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  30%|█████████████████████▉                                                   | 45/150 [00:07<00:14,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_44.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_44.tif - Class 'group_of_trees' - 3 polygons detected\n",
      "20cm_evaluation_45.tif - Class 'individual_tree' - 5 polygons detected\n",
      "20cm_evaluation_45.tif - Class 'group_of_trees' - 5 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  31%|██████████████████████▊                                                  | 47/150 [00:08<00:14,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_46.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_46.tif - Class 'group_of_trees' - 2 polygons detected\n",
      "20cm_evaluation_47.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_47.tif - Class 'group_of_trees' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  33%|███████████████████████▊                                                 | 49/150 [00:08<00:13,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_48.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_48.tif - Class 'group_of_trees' - 6 polygons detected\n",
      "20cm_evaluation_49.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_49.tif - Class 'group_of_trees' - 5 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  33%|████████████████████████▎                                                | 50/150 [00:08<00:15,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_50.tif - Class 'individual_tree' - 17 polygons detected\n",
      "20cm_evaluation_50.tif - Class 'group_of_trees' - 9 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  35%|█████████████████████████▎                                               | 52/150 [00:09<00:17,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_51.tif - Class 'individual_tree' - 25 polygons detected\n",
      "20cm_evaluation_51.tif - Class 'group_of_trees' - 8 polygons detected\n",
      "20cm_evaluation_52.tif - Class 'individual_tree' - 2 polygons detected\n",
      "20cm_evaluation_52.tif - Class 'group_of_trees' - 24 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  35%|█████████████████████████▊                                               | 53/150 [00:09<00:21,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_53.tif - Class 'individual_tree' - 57 polygons detected\n",
      "20cm_evaluation_53.tif - Class 'group_of_trees' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  36%|██████████████████████████▎                                              | 54/150 [00:09<00:24,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_54.tif - Class 'individual_tree' - 52 polygons detected\n",
      "20cm_evaluation_54.tif - Class 'group_of_trees' - 8 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  37%|███████████████████████████▎                                             | 56/150 [00:10<00:20,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_55.tif - Class 'individual_tree' - 24 polygons detected\n",
      "20cm_evaluation_55.tif - Class 'group_of_trees' - 12 polygons detected\n",
      "20cm_evaluation_56.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_56.tif - Class 'group_of_trees' - 25 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  39%|████████████████████████████▏                                            | 58/150 [00:10<00:16,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_57.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_57.tif - Class 'group_of_trees' - 1 polygons detected\n",
      "20cm_evaluation_58.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_58.tif - Class 'group_of_trees' - 0 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  40%|█████████████████████████████▏                                           | 60/150 [00:10<00:13,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_59.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_59.tif - Class 'group_of_trees' - 0 polygons detected\n",
      "20cm_evaluation_60.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_60.tif - Class 'group_of_trees' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  41%|██████████████████████████████▏                                          | 62/150 [00:10<00:12,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_61.tif - Class 'individual_tree' - 8 polygons detected\n",
      "20cm_evaluation_61.tif - Class 'group_of_trees' - 1 polygons detected\n",
      "20cm_evaluation_62.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_62.tif - Class 'group_of_trees' - 0 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  43%|███████████████████████████████▏                                         | 64/150 [00:11<00:11,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_63.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_63.tif - Class 'group_of_trees' - 9 polygons detected\n",
      "20cm_evaluation_64.tif - Class 'individual_tree' - 5 polygons detected\n",
      "20cm_evaluation_64.tif - Class 'group_of_trees' - 6 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  44%|████████████████████████████████                                         | 66/150 [00:11<00:12,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_65.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_65.tif - Class 'group_of_trees' - 1 polygons detected\n",
      "20cm_evaluation_66.tif - Class 'individual_tree' - 4 polygons detected\n",
      "20cm_evaluation_66.tif - Class 'group_of_trees' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  45%|█████████████████████████████████                                        | 68/150 [00:11<00:11,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_67.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_67.tif - Class 'group_of_trees' - 2 polygons detected\n",
      "20cm_evaluation_68.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_68.tif - Class 'group_of_trees' - 0 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  47%|██████████████████████████████████                                       | 70/150 [00:11<00:10,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_69.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_69.tif - Class 'group_of_trees' - 0 polygons detected\n",
      "20cm_evaluation_70.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_70.tif - Class 'group_of_trees' - 7 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  48%|███████████████████████████████████                                      | 72/150 [00:12<00:10,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_71.tif - Class 'individual_tree' - 10 polygons detected\n",
      "20cm_evaluation_71.tif - Class 'group_of_trees' - 2 polygons detected\n",
      "20cm_evaluation_72.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_72.tif - Class 'group_of_trees' - 10 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  49%|████████████████████████████████████                                     | 74/150 [00:12<00:10,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_73.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_73.tif - Class 'group_of_trees' - 3 polygons detected\n",
      "20cm_evaluation_74.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_74.tif - Class 'group_of_trees' - 4 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  51%|████████████████████████████████████▉                                    | 76/150 [00:12<00:09,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20cm_evaluation_75.tif - Class 'individual_tree' - 1 polygons detected\n",
      "20cm_evaluation_75.tif - Class 'group_of_trees' - 1 polygons detected\n",
      "40cm_evaluation_100.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_100.tif - Class 'group_of_trees' - 2 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  52%|█████████████████████████████████████▉                                   | 78/150 [00:12<00:08,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_76.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_76.tif - Class 'group_of_trees' - 0 polygons detected\n",
      "40cm_evaluation_77.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_77.tif - Class 'group_of_trees' - 15 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  53%|██████████████████████████████████████▉                                  | 80/150 [00:13<00:09,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_78.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_78.tif - Class 'group_of_trees' - 16 polygons detected\n",
      "40cm_evaluation_79.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_79.tif - Class 'group_of_trees' - 13 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  55%|███████████████████████████████████████▉                                 | 82/150 [00:13<00:09,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_80.tif - Class 'individual_tree' - 6 polygons detected\n",
      "40cm_evaluation_80.tif - Class 'group_of_trees' - 18 polygons detected\n",
      "40cm_evaluation_81.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_81.tif - Class 'group_of_trees' - 14 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  56%|████████████████████████████████████████▉                                | 84/150 [00:13<00:08,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_82.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_82.tif - Class 'group_of_trees' - 11 polygons detected\n",
      "40cm_evaluation_83.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_83.tif - Class 'group_of_trees' - 4 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  57%|█████████████████████████████████████████▊                               | 86/150 [00:14<00:08,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_84.tif - Class 'individual_tree' - 3 polygons detected\n",
      "40cm_evaluation_84.tif - Class 'group_of_trees' - 11 polygons detected\n",
      "40cm_evaluation_85.tif - Class 'individual_tree' - 6 polygons detected\n",
      "40cm_evaluation_85.tif - Class 'group_of_trees' - 2 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  59%|██████████████████████████████████████████▊                              | 88/150 [00:14<00:07,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_86.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_86.tif - Class 'group_of_trees' - 3 polygons detected\n",
      "40cm_evaluation_87.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_87.tif - Class 'group_of_trees' - 15 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  60%|███████████████████████████████████████████▊                             | 90/150 [00:14<00:07,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_88.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_88.tif - Class 'group_of_trees' - 10 polygons detected\n",
      "40cm_evaluation_89.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_89.tif - Class 'group_of_trees' - 12 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  61%|████████████████████████████████████████████▊                            | 92/150 [00:14<00:08,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_90.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_90.tif - Class 'group_of_trees' - 4 polygons detected\n",
      "40cm_evaluation_91.tif - Class 'individual_tree' - 4 polygons detected\n",
      "40cm_evaluation_91.tif - Class 'group_of_trees' - 19 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  63%|█████████████████████████████████████████████▋                           | 94/150 [00:15<00:07,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_92.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_92.tif - Class 'group_of_trees' - 13 polygons detected\n",
      "40cm_evaluation_93.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_93.tif - Class 'group_of_trees' - 11 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  64%|██████████████████████████████████████████████▋                          | 96/150 [00:15<00:07,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_94.tif - Class 'individual_tree' - 2 polygons detected\n",
      "40cm_evaluation_94.tif - Class 'group_of_trees' - 28 polygons detected\n",
      "40cm_evaluation_95.tif - Class 'individual_tree' - 3 polygons detected\n",
      "40cm_evaluation_95.tif - Class 'group_of_trees' - 12 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  65%|███████████████████████████████████████████████▋                         | 98/150 [00:15<00:06,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_96.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_96.tif - Class 'group_of_trees' - 8 polygons detected\n",
      "40cm_evaluation_97.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_97.tif - Class 'group_of_trees' - 0 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  67%|████████████████████████████████████████████████                        | 100/150 [00:15<00:06,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40cm_evaluation_98.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_98.tif - Class 'group_of_trees' - 5 polygons detected\n",
      "40cm_evaluation_99.tif - Class 'individual_tree' - 1 polygons detected\n",
      "40cm_evaluation_99.tif - Class 'group_of_trees' - 13 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  68%|████████████████████████████████████████████████▉                       | 102/150 [00:16<00:06,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_101.tif - Class 'individual_tree' - 2 polygons detected\n",
      "60cm_evaluation_101.tif - Class 'group_of_trees' - 23 polygons detected\n",
      "60cm_evaluation_102.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_102.tif - Class 'group_of_trees' - 9 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  69%|█████████████████████████████████████████████████▉                      | 104/150 [00:16<00:06,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_103.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_103.tif - Class 'group_of_trees' - 24 polygons detected\n",
      "60cm_evaluation_104.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_104.tif - Class 'group_of_trees' - 8 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  70%|██████████████████████████████████████████████████▍                     | 105/150 [00:16<00:05,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_105.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_105.tif - Class 'group_of_trees' - 26 polygons detected\n",
      "60cm_evaluation_106.tif - Class 'individual_tree' - 2 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  71%|███████████████████████████████████████████████████▎                    | 107/150 [00:16<00:06,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_106.tif - Class 'group_of_trees' - 40 polygons detected\n",
      "60cm_evaluation_107.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_107.tif - Class 'group_of_trees' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  72%|███████████████████████████████████████████████████▊                    | 108/150 [00:17<00:06,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_108.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_108.tif - Class 'group_of_trees' - 11 polygons detected\n",
      "60cm_evaluation_109.tif - Class 'individual_tree' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  73%|████████████████████████████████████████████████████▊                   | 110/150 [00:17<00:06,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_109.tif - Class 'group_of_trees' - 22 polygons detected\n",
      "60cm_evaluation_110.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_110.tif - Class 'group_of_trees' - 19 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  75%|█████████████████████████████████████████████████████▊                  | 112/150 [00:17<00:06,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_111.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_111.tif - Class 'group_of_trees' - 18 polygons detected\n",
      "60cm_evaluation_112.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_112.tif - Class 'group_of_trees' - 30 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  75%|██████████████████████████████████████████████████████▏                 | 113/150 [00:17<00:06,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_113.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_113.tif - Class 'group_of_trees' - 46 polygons detected\n",
      "60cm_evaluation_114.tif - Class 'individual_tree' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  77%|███████████████████████████████████████████████████████▏                | 115/150 [00:18<00:05,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_114.tif - Class 'group_of_trees' - 82 polygons detected\n",
      "60cm_evaluation_115.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_115.tif - Class 'group_of_trees' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  77%|███████████████████████████████████████████████████████▋                | 116/150 [00:18<00:05,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_116.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_116.tif - Class 'group_of_trees' - 27 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  78%|████████████████████████████████████████████████████████▏               | 117/150 [00:18<00:06,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_117.tif - Class 'individual_tree' - 16 polygons detected\n",
      "60cm_evaluation_117.tif - Class 'group_of_trees' - 41 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  79%|████████████████████████████████████████████████████████▋               | 118/150 [00:18<00:06,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_118.tif - Class 'individual_tree' - 4 polygons detected\n",
      "60cm_evaluation_118.tif - Class 'group_of_trees' - 54 polygons detected\n",
      "60cm_evaluation_119.tif - Class 'individual_tree' - 5 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  79%|█████████████████████████████████████████████████████████               | 119/150 [00:19<00:06,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_119.tif - Class 'group_of_trees' - 57 polygons detected\n",
      "60cm_evaluation_120.tif - Class 'individual_tree' - 11 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  81%|██████████████████████████████████████████████████████████              | 121/150 [00:19<00:05,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_120.tif - Class 'group_of_trees' - 54 polygons detected\n",
      "60cm_evaluation_121.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_121.tif - Class 'group_of_trees' - 21 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  82%|███████████████████████████████████████████████████████████             | 123/150 [00:19<00:04,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_122.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_122.tif - Class 'group_of_trees' - 13 polygons detected\n",
      "60cm_evaluation_123.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_123.tif - Class 'group_of_trees' - 18 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  83%|███████████████████████████████████████████████████████████▌            | 124/150 [00:20<00:04,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_124.tif - Class 'individual_tree' - 1 polygons detected\n",
      "60cm_evaluation_124.tif - Class 'group_of_trees' - 43 polygons detected\n",
      "60cm_evaluation_125.tif - Class 'individual_tree' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  84%|████████████████████████████████████████████████████████████▍           | 126/150 [00:20<00:04,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60cm_evaluation_125.tif - Class 'group_of_trees' - 4 polygons detected\n",
      "80cm_evaluation_126.tif - Class 'individual_tree' - 3 polygons detected\n",
      "80cm_evaluation_126.tif - Class 'group_of_trees' - 37 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  85%|█████████████████████████████████████████████████████████████▍          | 128/150 [00:20<00:03,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_127.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_127.tif - Class 'group_of_trees' - 1 polygons detected\n",
      "80cm_evaluation_128.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_128.tif - Class 'group_of_trees' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  86%|█████████████████████████████████████████████████████████████▉          | 129/150 [00:20<00:03,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_129.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_129.tif - Class 'group_of_trees' - 26 polygons detected\n",
      "80cm_evaluation_130.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_130.tif - Class 'group_of_trees' - 0 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  88%|███████████████████████████████████████████████████████████████▎        | 132/150 [00:21<00:02,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_131.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_131.tif - Class 'group_of_trees' - 3 polygons detected\n",
      "80cm_evaluation_132.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_132.tif - Class 'group_of_trees' - 0 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  89%|████████████████████████████████████████████████████████████████▎       | 134/150 [00:21<00:01,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_133.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_133.tif - Class 'group_of_trees' - 8 polygons detected\n",
      "80cm_evaluation_134.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_134.tif - Class 'group_of_trees' - 2 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  91%|█████████████████████████████████████████████████████████████████▎      | 136/150 [00:21<00:01,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_135.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_135.tif - Class 'group_of_trees' - 8 polygons detected\n",
      "80cm_evaluation_136.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_136.tif - Class 'group_of_trees' - 25 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  91%|█████████████████████████████████████████████████████████████████▊      | 137/150 [00:21<00:01,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_137.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_137.tif - Class 'group_of_trees' - 8 polygons detected\n",
      "80cm_evaluation_138.tif - Class 'individual_tree' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  93%|██████████████████████████████████████████████████████████████████▋     | 139/150 [00:22<00:01,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_138.tif - Class 'group_of_trees' - 45 polygons detected\n",
      "80cm_evaluation_139.tif - Class 'individual_tree' - 4 polygons detected\n",
      "80cm_evaluation_139.tif - Class 'group_of_trees' - 13 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  94%|███████████████████████████████████████████████████████████████████▋    | 141/150 [00:22<00:01,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_140.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_140.tif - Class 'group_of_trees' - 0 polygons detected\n",
      "80cm_evaluation_141.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_141.tif - Class 'group_of_trees' - 6 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  95%|████████████████████████████████████████████████████████████████████▏   | 142/150 [00:22<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_142.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_142.tif - Class 'group_of_trees' - 0 polygons detected\n",
      "80cm_evaluation_143.tif - Class 'individual_tree' - 1 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  96%|█████████████████████████████████████████████████████████████████████   | 144/150 [00:22<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_143.tif - Class 'group_of_trees' - 66 polygons detected\n",
      "80cm_evaluation_144.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_144.tif - Class 'group_of_trees' - 29 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  97%|██████████████████████████████████████████████████████████████████████  | 146/150 [00:23<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_145.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_145.tif - Class 'group_of_trees' - 7 polygons detected\n",
      "80cm_evaluation_146.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_146.tif - Class 'group_of_trees' - 6 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images:  99%|███████████████████████████████████████████████████████████████████████ | 148/150 [00:23<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_147.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_147.tif - Class 'group_of_trees' - 42 polygons detected\n",
      "80cm_evaluation_148.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_148.tif - Class 'group_of_trees' - 3 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images: 100%|████████████████████████████████████████████████████████████████████████| 150/150 [00:23<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80cm_evaluation_149.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_149.tif - Class 'group_of_trees' - 23 polygons detected\n",
      "80cm_evaluation_150.tif - Class 'individual_tree' - 1 polygons detected\n",
      "80cm_evaluation_150.tif - Class 'group_of_trees' - 4 polygons detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All evaluation predictions saved to: data\\test\\evaluation_images\\jsons\\unet_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from shapely.geometry import Polygon, box\n",
    "import torch\n",
    "from tqdm import tqdm  # progress bar\n",
    "import cv2\n",
    "\n",
    "# --- CONFIG ---\n",
    "EVAL_DIR = Path(\"data/test/evaluation_images\")  # Folder with evaluation images\n",
    "OUTPUT_JSON_PATH = EVAL_DIR / \"jsons/unet_evaluation.json\"  # Single JSON file\n",
    "CONFIDENCE_METHOD = 'mean'  # How to assign confidence score for each polygon\n",
    "CLASSES = [\"individual_tree\", \"group_of_trees\"]  # Must match your model\n",
    "DEBUG = True  # Set False to disable prints\n",
    "\n",
    "def mask_to_polygons_with_scores(mask, confidence_map, min_area=10):\n",
    "    \"\"\"\n",
    "    Convert binary mask to list of (Polygon, confidence_score)\n",
    "    Each polygon is simplified to 4 points (bounding box)\n",
    "    \"\"\"\n",
    "    polygons_with_scores = []\n",
    "    mask_uint8 = (mask > 0.5).astype(np.uint8) * 255\n",
    "    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < min_area:\n",
    "            continue\n",
    "        \n",
    "        # Compute minimum bounding rectangle\n",
    "        rect = cv2.minAreaRect(cnt)  # ((cx,cy),(w,h),angle)\n",
    "        box_pts = cv2.boxPoints(rect)  # 4 points, float32\n",
    "        poly = Polygon(box_pts)\n",
    "        \n",
    "        # Confidence score: mean of mask under this contour\n",
    "        mask_indices = mask_uint8 > 0\n",
    "        score = confidence_map[mask_indices].mean() if CONFIDENCE_METHOD=='mean' else 1.0\n",
    "        polygons_with_scores.append((poly, float(score)))\n",
    "    \n",
    "    return polygons_with_scores\n",
    "\n",
    "# --- Run inference ---\n",
    "model.eval()\n",
    "all_images_json = []\n",
    "\n",
    "print(\"Starting evaluation on images...\")\n",
    "for img_path in tqdm(sorted(EVAL_DIR.glob(\"*.tif\")), desc=\"Images\"):\n",
    "    image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "    image_tensor = train_transform(image=image)['image'].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)  # [B, C, H, W]\n",
    "    output_np = output.squeeze(0).cpu().numpy()  # [C, H, W]\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    for cls_idx, class_name in enumerate(CLASSES):\n",
    "        class_mask = (output_np[cls_idx] > 0.5).astype(np.uint8)\n",
    "        pred_polys = mask_to_polygons_with_scores(class_mask, output_np[cls_idx])\n",
    "\n",
    "        if DEBUG:\n",
    "            print(f\"{img_path.name} - Class '{class_name}' - {len(pred_polys)} polygons detected\")\n",
    "\n",
    "        for poly, score in pred_polys:\n",
    "            coords = np.array(poly.exterior.coords).flatten().tolist()[:8]  # only first 4 points\n",
    "            annotations.append({\n",
    "                \"class\": class_name,\n",
    "                \"confidence_score\": float(score),\n",
    "                \"segmentation\": [float(c) for c in coords]\n",
    "            })\n",
    "\n",
    "    all_images_json.append({\n",
    "        \"file_name\": img_path.name,\n",
    "        \"width\": image.shape[1],\n",
    "        \"height\": image.shape[0],\n",
    "        \"cm_resolution\": 10,  # adjust if known\n",
    "        \"scene_type\": \"unknown\",\n",
    "        \"annotations\": annotations\n",
    "    })\n",
    "\n",
    "# Save all images in a single JSON file\n",
    "OUTPUT_JSON_PATH.parent.mkdir(exist_ok=True, parents=True)\n",
    "with open(OUTPUT_JSON_PATH, \"w\") as f:\n",
    "    json.dump({\"images\": all_images_json}, f, indent=4)\n",
    "\n",
    "print(f\"\\nAll evaluation predictions saved to: {OUTPUT_JSON_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11613a6d-14b1-4f03-a344-7bc42aa5bcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet prediction saved to: data\\raw\\train_images\\jsons\\unet_train_image_predictions.json\n",
      "UNet polygons: 13\n"
     ]
    }
   ],
   "source": [
    "# Notebook: unet_train_image_prediction.ipynb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from shapely.geometry import Polygon\n",
    "import torch\n",
    "import cv2\n",
    "import segmentation_models_pytorch as smp\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "\n",
    "# --- CONFIG ---\n",
    "TRAIN_IMAGE = Path(\"data/raw/train_images/10cm_train_3.tif\")\n",
    "OUTPUT_JSON_PATH = Path(\"data/raw/train_images/jsons/unet_train_image_predictions.json\")\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "CLASSES = [\"individual_tree\", \"group_of_trees\"]\n",
    "UNET_MODEL_PATH = \"best_unet_model_multiclass.pth\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ------------------------------\n",
    "# Helper: Convert mask to polygons\n",
    "# ------------------------------\n",
    "def mask_to_polygons(mask, confidence_map=None, min_area=10):\n",
    "    polygons_with_scores = []\n",
    "    mask_uint8 = (mask > 0.5).astype(np.uint8) * 255\n",
    "    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) >= min_area:\n",
    "            poly = Polygon(cnt[:,0,:])\n",
    "            score = confidence_map[mask_uint8>0].mean() if confidence_map is not None else 1.0\n",
    "            polygons_with_scores.append((poly, float(score)))\n",
    "    return polygons_with_scores\n",
    "\n",
    "# ------------------------------\n",
    "# Load UNet model\n",
    "# ------------------------------\n",
    "transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "model_unet = smp.Unet(\n",
    "    encoder_name='resnet18',\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=len(CLASSES),\n",
    "    activation='softmax'\n",
    ").to(DEVICE)\n",
    "model_unet.load_state_dict(torch.load(UNET_MODEL_PATH, map_location=DEVICE))\n",
    "model_unet.eval()\n",
    "\n",
    "# ------------------------------\n",
    "# Run prediction\n",
    "# ------------------------------\n",
    "image_np = np.array(Image.open(TRAIN_IMAGE).convert(\"RGB\"))\n",
    "image_tensor = transform(image=image_np)['image'].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model_unet(image_tensor)\n",
    "output_np = output.squeeze(0).cpu().numpy()\n",
    "\n",
    "annotations_unet = []\n",
    "for cls_idx, class_name in enumerate(CLASSES):\n",
    "    mask = (output_np[cls_idx] > CONFIDENCE_THRESHOLD).astype(np.uint8)\n",
    "    polys = mask_to_polygons(mask, confidence_map=output_np[cls_idx])\n",
    "    for poly, score in polys:\n",
    "        coords = np.array(poly.exterior.coords).flatten().tolist()\n",
    "        annotations_unet.append({\n",
    "            \"class\": class_name,\n",
    "            \"confidence_score\": float(score),\n",
    "            \"segmentation\": [float(c) for c in coords]\n",
    "        })\n",
    "\n",
    "# ------------------------------\n",
    "# Save JSON\n",
    "# ------------------------------\n",
    "output_json = {\n",
    "    \"file_name\": TRAIN_IMAGE.name,\n",
    "    \"width\": image_np.shape[1],\n",
    "    \"height\": image_np.shape[0],\n",
    "    \"cm_resolution\": 10,\n",
    "    \"scene_type\": \"unknown\",\n",
    "    \"annotations_unet\": annotations_unet\n",
    "}\n",
    "\n",
    "OUTPUT_JSON_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUTPUT_JSON_PATH, 'w') as f:\n",
    "    json.dump(output_json, f, indent=4)\n",
    "\n",
    "print(f\"UNet prediction saved to: {OUTPUT_JSON_PATH}\")\n",
    "print(f\"UNet polygons: {len(annotations_unet)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e87eed-ebbf-41a4-bd28-d3140b5122b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py311 GPU",
   "language": "python",
   "name": "py311_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
